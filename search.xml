<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux系统命令总结--查看文件内容]]></title>
    <url>%2F2019%2F09%2F19%2FLinux%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93-%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[Linux系统命令总结–查看文件内容查看文件类型 file命令file命令file --help 1234567891011121314151617181920212223242526272829303132333435363738394041424344Usage: file [OPTION...] [FILE...]Determine type of FILEs. --help display this help and exit -v, --version output version information and exit -m, --magic-file LIST use LIST as a colon-separated list of magic number files -z, --uncompress try to look inside compressed files -Z, --uncompress-noreport only print the contents of compressed files -b, --brief do not prepend filenames to output lines -c, --checking-printout print the parsed form of the magic file, use in conjunction with -m to debug a new magic file before installing it -e, --exclude TEST exclude TEST from the list of test to be performed for file. Valid tests are: apptype, ascii, cdf, compress, elf, encoding, soft, tar, text, tokens -f, --files-from FILE read the filenames to be examined from FILE -F, --separator STRING use string as separator instead of `:' -i, --mime output MIME type strings (--mime-type and --mime-encoding) --apple output the Apple CREATOR/TYPE --extension output a slash-separated list of extensions --mime-type output the MIME type --mime-encoding output the MIME encoding -k, --keep-going don't stop at the first match -l, --list list magic strength -L, --dereference follow symlinks (default if POSIXLY_CORRECT is set) -h, --no-dereference don't follow symlinks (default if POSIXLY_CORRECT is not set) (default) -n, --no-buffer do not buffer output -N, --no-pad do not pad output -0, --print0 terminate filenames with ASCII NUL -p, --preserve-date preserve access times on files -P, --parameter set file engine parameter limits indir 15 recursion limit for indirection name 30 use limit for name/use magic elf_notes 256 max ELF notes processed elf_phnum 128 max ELF prog sections processed elf_shnum 32768 max ELF sections processed -r, --raw don't translate unprintable chars to \ooo -s, --special-files treat special (block/char devices) files as ordinary ones -C, --compile compile file specified by -m -d, --debug print debugging messages file命令主要用来查看文件的类型。 | 参数 | 作用 || —- | ———————————————————— || -b | 结果不输出文件名 || -z | 尝试解压压缩文件 || -f | 指定名称文件，其中内容有一个或者多个文件名称时，依序辨识这些文件 || -L | 直接显示符号链接指向的文件 || -v | 显示版本信息 || | || | | 查看文件内容 cat命令 cat --help 显示cat命令帮助 1234567891011121314151617Usage: cat [OPTION]... [FILE]...Concatenate FILE(s) to standard output.With no FILE, or when FILE is -, read standard input. -A, --show-all equivalent to -vET -b, --number-nonblank number nonempty output lines, overrides -n -e equivalent to -vE -E, --show-ends display $ at end of each line -n, --number number all output lines -s, --squeeze-blank suppress repeated empty output lines -t equivalent to -vT -T, --show-tabs display TAB characters as ^I -u (ignored) -v, --show-nonprinting use ^ and M- notation, except for LFD and TAB --help display this help and exit --version output version information and exit cat相关命令 12345678910111213141516171819202122232425262728293031323334353637#查看文件$ cat test.shecho date;#-n参数给所有行加上行号$ cat -n test.sh 1 echo date;#只给有文本的行加上行号，可以用-b参数$ cat -b test.sh 1 echo date; 2 echo time; #如果不想出现制表符，可以用-T参数，-T参数会用^I字符组合去替换文中的所有制表符$ cat -T test.shecho date;echo time;#使用-s参数来去除多余的空行，原来文件之间有多个空行$ cat -s test.shecho date;echo time;#使用-e参数来使得每一行的末尾都以$结尾$ cat -e test.shecho date;$$$$$$$$echo time;$ more命令cat的缺陷在于一旦运行就无法控制后面操作，为了解决这个问题，开发人员编写了more命令。more命令会显示文本文件的内容，但是会在显示每页数据之后停下来。 more --help 12345678910111213141516Usage: more [options] &lt;file&gt;...A file perusal filter for CRT viewing.Options: -d display help instead of ringing bell -f count logical rather than screen lines -l suppress pause after form feed -c do not scroll, display text and clean line ends -p do not scroll, clean screen and display text -s squeeze multiple blank lines into one -u suppress underlining -&lt;number&gt; the number of lines per screenful +&lt;number&gt; display file beginning from line number +/&lt;string&gt; display file beginning from search string match more命令的相关参数 123456789# more命令的相关参数,显示相关帮助信息more -d test.sh...222222--More--(16%)[Press space to continue, 'q' to quit.]# more命令-f参数... less命令less 命令实际上是more命令的升级版（名称由俗语less is more得来）， 查看部分文件 tail命令tail命令tail --help 1234567891011121314151617181920212223242526272829303132Usage: tail [OPTION]... [FILE]...Print the last 10 lines of each FILE to standard output.With more than one FILE, precede each with a header giving the file name.With no FILE, or when FILE is -, read standard input.Mandatory arguments to long options are mandatory for short options too. -c, --bytes=[+]NUM output the last NUM bytes; or use -c +NUM to output starting with byte NUM of each file -f, --follow[=&#123;name|descriptor&#125;] output appended data as the file grows; an absent option argument means 'descriptor' -F same as --follow=name --retry -n, --lines=[+]NUM output the last NUM lines, instead of the last 10; or use -n +NUM to output starting with line NUM --max-unchanged-stats=N with --follow=name, reopen a FILE which has not changed size after N (default 5) iterations to see if it has been unlinked or renamed (this is the usual case of rotated log files); with inotify, this option is rarely useful --pid=PID with -f, terminate after process ID, PID dies -q, --quiet, --silent never output headers giving file names --retry keep trying to open a file if it is inaccessible -s, --sleep-interval=N with -f, sleep for approximately N seconds (default 1.0) between iterations; with inotify and --pid=P, check process P at least once every N seconds -v, --verbose always output headers giving file names -z, --zero-terminated line delimiter is NUL, not newline --help display this help and exit --version output version information and exit tail命令：显示文件最后几行的内容。默认显示文件末尾10行。 比如我们创建了一个包含20行文本的文本文件。使用cat命令显示该文件的全部内容如下： 12345678910111213141516171819202122$ cat log_fileline1line2line3line4line5Hello World - line 6line7line8line9line10line11Hello again - line 12line13line14line15Sweet - line16line17line18line19Last line - line20$ 现在显示的是整个文件，使用tail命令浏览文件最后10行的效果： 123456789101112$ tail log_fileline11Hello again - line 12line13line14line15Sweet - line16line17line18line19Last line - line20$ 可以向tail命令加入-n参数来修改所显示的行数。下面的例子中，通过加入-n 2使tail命令只显示文件的最后两行。 1234$ tail -n 2 log_fileline19Last line - line20$ 还可以在通过tail命令 加号显示某行之后的行数 123456789101112$ tail -n +10 log_fileline10line11Hello again - line 12line13line14line15Sweet - line16line17line18line19Last line - line20 -f参数是tail命令的一个突出特性，允许你在其他进程中使用该文件时查看文件的内容。tail会保持活动状态，并且不断的显示添加文件中的内容。 head命令首先通过head --help来查看head命令的使用方法 123456789101112131415161718Usage: head [OPTION]... [FILE]...Print the first 10 lines of each FILE to standard output.With more than one FILE, precede each with a header giving the file name.With no FILE, or when FILE is -, read standard input.Mandatory arguments to long options are mandatory for short options too. -c, --bytes=[-]NUM print the first NUM bytes of each file; with the leading '-', print all but the last NUM bytes of each file -n, --lines=[-]NUM print the first NUM lines instead of the first 10; with the leading '-', print all but the last NUM lines of each file -q, --quiet, --silent never print headers giving file names -v, --verbose always print headers giving file names -z, --zero-terminated line delimiter is NUL, not newline --help display this help and exit --version output version information and exit head命令查看文件的前10行 123456789101112$ head log_fileline1line2line3line4line5Hello World - line 6line7line8line9line10$ 也可以使用参数-n 来指定显示的行数,比如head -n 5 log_file显示log_file的前5行 123456$ head -n 5 log_fileline1line2line3line4line5 也可以通过添加减号，指定不显示最后几行，比如head -n -5 log_file 12345678910111213141516$ head -n -5 log_fileline1line2line3line4line5Hello World - line 6line7line8line9line10line11Hello again - line 12line13line14line15 一般文件头不会发生变化，所以没有-f参数 head和tail命令的组合使用比如你想显示某个文件的第10行，我们可以组合使用head和tail命令 12$ tail -n +10 log_file |head -n 1line10 再比如从第11行显示，但是不包括最后三行 12345678$ head -n -3 log_file | tail -n +11line11Hello again - line 12line13line14line15Sweet - line16line17 再比如显示前20行，但是从第11行开始 1234567891011$ head -n 20 log_file | tail -n +11line11Hello again - line 12line13line14line15Sweet - line16line17line18line19Last line - line20 可以看出，组合head和tail命令可以产生更加强大的功能。 参考文献《Linux命令行和shell脚本编程大全》]]></content>
      <categories>
        <category>操作系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux硬链接和软链接]]></title>
    <url>%2F2019%2F08%2F30%2FLinux%E7%A1%AC%E9%93%BE%E6%8E%A5%E5%92%8C%E8%BD%AF%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[Linux连接概念linux的链接分为两种，一种被称为硬链接（Hard Linx），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 什么是链接链接简单说是一种文件共享的方式，是POSIX中的概念，主流文件系统都支持连接文件。 链接的作用链接可以简单的理解为windows中常见的快捷方式， Linux中常用它来解决一些库版本的问题，通常也会将一些目录层次较深的文件链接到一个更加容易访问的目录中。在这些用途上，我们通常会使用软链接（也成为符号链接）。 inode定义inode指的是Linux系统中用作数据索引的标识符。 inode指示了一个文件的基本信息：inode编号，修改时间，文件位置等。 如同同一本书的目录，会直接告诉你想看的章节在第几页。Linux和书不同的是，Linux文件存取是以块为单位的。 操作系统在读取硬盘时，会一次性读取一个块，而inode就告诉了文件位于哪个块，于是系统就会从这个块开始读取内容，我们就可以看出这个文件的内容。 在系统内部，打开一个文件分为三步： 系统找到文件名对应的inode号 通过inode号，获取inode信息 根据inode信息，找到文件数据所在的块，读取内容。 inode内容基本信息： 文件字节数 inode编号 文件拥有者Uid 文件所属group的Gid 文件的读，写，执行权限 文件的时间戳： change:上次变动时间 modify：文件内容上一次变动时间 access：文件上一次打开的时间 链接数量：即有多少文件名指向这个inode 文件数据块的位置 硬链接硬链接通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管什么类型都分配一个inode。 Linux中，多个文件名指向同一个索引节点是存在的，比如：A是B的硬链接，则A的目录项的inode节点号与B的目录项的inode节点号相同。即一个inode节点对应两个不同的文件名，两个文件名指向同一个文件。A和B对文件系统来说是完全平等的，删除任何一个不会影响另一个访问。 硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。 只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。 软链接另外一种链接称为符号链接，也叫软链接，类似于Windows的快捷方式。实际上是特殊的文件，在符号链接中，文件实际上是一个文本文件，包含另一个文件的位置信息。比如A是B的软链接，A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号不相同，A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）。A 和 B 之间是“主从”关系，如果 B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。 软硬链接的不同 本质不同：硬连接指向同一个文件，而软连接指向的不是同一个文件 删除时：硬连接不受影响，软连接失效 创建链接时：创建硬链接链接数加1，创建软链接连接数不变 跨分区：硬链接不可以跨分区，软链接可以跨分区 目录是否可以创建链接：硬链接不可以对目录创建，软链接可以对目录创建 硬连接的inode号相同，软链接inode号不同 参考文献linux链接概念 理解Linux的硬链接与软链接 深入讲解 linux 中 inode、硬链接、软链接的原理]]></content>
      <categories>
        <category>操作系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP可靠传输和拥塞控制]]></title>
    <url>%2F2019%2F08%2F19%2FTCP%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E5%92%8C%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[TCP可靠传输和拥塞控制机制TCP可靠传输数据流传输方式TCP数据一般分为：交互数据和成块数据，交互数据一般比较小，比如发送一个字节的交互数据，加上TCP数据段首部以及IP数据包首部，至少需要41个字节。 交互数据流传输互联网早期通信链路并不可靠，因此在链路层传输数据的时候要采取可靠的传输协议。其中最简单的为停止等待协议。传输层并不使用停止等待协议，但是传输交互数据流传输时采用nagle算法和该协议原理很类似。 停止等待协议 每一次发送完一个分组就停止发送，等待对方确认。 发送放发送数据分组A，接收方接收到A后，向发送方确认数据，发送方收到A确认后继续发送数据分组B。 数组分组在传输过程中发生错误时有两种情况： 接收方收到错误数据直接丢弃 数据分组在传输过程中丢失 这两种情况接收方都不会发送任何信息。发送方在一定时间内没有收到确认就会重传，这种叫超时重传。 nagle算法在传输交互数据流一般用nagle算法。nagle算法要求在一个TCP连接上最多只能有一个未被确认的小分组。在该分组确认到达之前不能发送其他分组。 在收到确认之后并不是立刻发送其他分组，TCP连接允许不存在数据分组。具体的nagle算法规则如下： 缓存中数据长度达到最大报文长度时，允许 发送。 缓存中数据长度达到发送窗口一半时，允许发送。 报文首部FIN标志为1的时候允许发送。 报文段首部设置了TCP_NODELAY选项，则允许发送。 发生了超时，立即发送。 成块数据流传输 成块数据流往往超过最大报文长度，要进行拆分之后再发送，交互数据碎片化的问题不会出现。成块数据是通过基于滑动窗口协议的连续ARQ协议完成的。 滑动窗口协议使用基于停止等待协议的nagle算法信道利用率太低。 如果使用流水线传输，那么信到利用率会大幅提升，TCP采用滑动窗口协议来实现流水线传输。 滑动窗户协议是指数据发送方有一个发送窗口，发送窗口范围内的数据允许发送，随着接收方传来的确认信息以及通知的接收窗口的大小来动态调整发送窗口的起始位置以及大小。 ​ 窗口有三种情况： 前沿向右移动，这种情况在数据发送并且被确认时 后沿向右移动，允许发送更多数据。发生于接收窗口增大或者网络拥塞情况缓解。 后沿向左移动，发生于接收方希望窗口缩小。 TCP要求接收方有累计确认功能，接收方不必立刻对收到的数据进行确认，这样可以减少传输开销。另外，在发送确认时也可以捎带上接收方要发送的数据。TCP标准规定确认推迟的时间不能超过0.5秒，如果收到一个具有最大报文长度的报文段，则必须隔一个报文段就发送一个确认。 累计确认只针对按序到达的最后一个分组发送确认。表示这个分组已经全部到达。 比如上图中序号5、6、7、9、10分组到达接收方，接收方发送的确认序号是8，即接收方没有收到序号8的分组，希望下次收到序号8的分组。而序号9、10分组虽然已经到达的事实，发送方并不知晓。 这会导致一个问题：一旦发生超时重传的情况，发送方是否需要再次发送已经到达的数据？如果不需要，又该如何获知具体哪些数据已经到达？ 后退N帧ARQ协议发生超时重传时，后退N帧ARQ协议不考虑确认序号之后的分组是否已经发送到接收方，直接从确认序号开始重传之后的数据。 选择重传ARQ协议选择重传指接收方收到未按序排列的数据流时，通知发送方重传缺失的数据，而不是重传全部的数据。 SR中窗口的大小必须小于等于分组序号的一半，不然很容易和新的分组混淆，接受法无法判断新传来的数据分组到底是上一个分组的数据还是新的分组的数据。 比如上图，收到了三个不连续的分组，这时候在TCP首部选项中加入”允许SACK“选项。在之后的TCP报文段增加SACK选项。 超时重传时间对于每一个连接，TCP管理4个不同的定时器： 重传定时器：决定何时重传未被确认的数据分组 坚持定时器：使窗口的大小信息保持不变 保活定时器：检测i空闲连接的另一端是否崩溃或重启 2MSL定时器：测量一个连接处于TIME_WAIT状态时间 在超时重传的情况下，如果将超时重传的时间设置的太短，会出现很多不必要的重传，增大网络负荷；如果设置的时间太长，则使网络的空闲时间增大，降低传输效率。TCP采用一种自适应的算法来动态计算超时重传的时间。 报文段往返时间一个报文段发出的时间和收到确认的时间差就是报文段的往返时间RTT。平滑的往返时间RTT_S是RTT的加权平均值。 Karn算法发送报文段后，在一定时间内没有收到确认。重传该报文段，之后收到确认报文。那么怎么确定确认报文是对哪个报文的确认？因为重传的报文和原报文完全相同，收到的确认报文也相同。那么报文段往返时间RTT是A还是B呢？ 在上述情况下，Karn提出一个算法：在计算加权平均RTT_S时，只要报文段重传了，就不采用其往返时间样本。这样的到的加权平均RTT_S和RTO就比较准确。 可靠数据传输机制及其用途的总结 机制 用途 检验和 用于检测在一个传输分组中的比特错误 定时器 用于检测超时/重传一个分组，因为该分组（或者ACK）在信道中丢失了。由于当一个分组延时但未丢失，或者一个分组已经被接收方收到但从接收方到发送方的ACK丢失时，可能产生超时事件，所以接收方可能会收到一个分组的多个冗余拷贝 序号 用于为发送方流向接收方的数据分组按顺序编号。所接收分组的序号间的空隙可使该接收方检测出丢失的分组。具有相同序号的分组可是接受方检测出一个分组的冗余拷贝。 确认 接收方告知发送方分组被正确接受。确认报文通常携带被确认分组或者多个分组序号，确认可以是逐个或者累计的，取决于协议。 否定确认 接收方用于告知发送方某个分组未被正确的接收，否定确认报文通常携带者未被正确接收的分组的序号 窗口 发送方被限制仅发送指定范围内序号的分组。通过允许一次发送多个分组但未被确认。 TCP流量控制流量控制一条TCP连接的双方主机都为该连接设置了接收缓存，当该TCP连接接收正确，按序的字节后，它就将数据放入接收缓存。如果发送方发送数据太快而接收方读取速度缓慢，很容易使得缓存溢出。TCP为应用程序提供了 流量控制服务，来匹配接收方和发送法的速率。 TCP通过让发送方维护一个接收窗口的变量来提供流量控制，用于告诉发送方接收方还有多少缓存。 发送方轮流跟踪两个变量LastByteSent(最后一个发送序号)和LastByteAcked(最后一个确认序号),这两个变量的差值就是发送方到接收方之间未被确认的数据量，将未被确认的数据量控制在窗口大小以内就可以保证接收方缓存不会溢出。 流量控制死锁避免当发送者收到一个窗口为0的应答，发送者便停止发送，等待接受者下一个应答，但是如果这个时候一个窗口不为0的应答在传输过程中丢失，发送者一直等待，而接受者认为发送者收到应答，也等待接受新数据，这样就产生了死锁。 为了避免这样的情况，TCP使用了持续计数器，每当发送者收到一个零窗口的应答就启动计时器，时间一到就主动询问接收方窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。 TCP拥塞控制拥塞控制和流量控制的区别拥塞控制：作用于网络 ，防止过多的数据注入到网络中，避免网络负载过大的情况 流量控制：流量控制作用于接受者，控制发送者的发送速度从而使得接受者来得及接收，防止分组丢失。 端到端拥塞控制在端到端拥塞控制方法中，网络层没有为运输层拥塞控制显式支持。 TCP采用的方法就是让每一个发送方根据所感知到的网络拥塞程度来限制其向连接发送流量的速率。这需要解决三个问题 TCP如何限制发送流量速率 TCP如何感受网络的拥塞程度 TCP采用什么算法来控制发送的速率 为了解决第一个问题，TCP定义了一个变量CongWin（拥塞窗口），一个发送方的未被确认的数据为Math.min(RcvWindow, Congwindow)。 假设接受缓存足够大的情况下，未被确认数据量大小仅和ConWin有关，因此这个拥塞窗口的值就限制了发送方未被确认的数据量，因此间接的限制了发送方的发送速率。粗略考虑就是在一个RTT的时间内，发送方允许向该连接发送最多CongWin个字节数据。 下面考虑第二个问题，TCP如何感知网络中是否出现拥塞。 我们定义一个TCP发送方的丢包事件：要么出现超时，要么收到来自接受方的三个冗余ACK。因为网络中过度拥塞时，网络中路由器的缓存会溢出，导致TCP数据包被丢弃。丢弃数据包就会引发（超时或者冗余ACK）。 拥塞控制算法TCP感知到网络中的拥塞后，TCP要实现调节发送速率的算法，主要分为慢开始，拥塞避免，快重传，快恢复 慢开始算法 发送方维持拥塞窗口ConWin的变量，慢开始算法的思路就是不要一开始就发送大量的数据，先探测一下网路的拥塞程度，具体步骤如下 初始化拥塞窗口的大小为1，表示可以传送一个MSS大小的数据（MSS：最大报文长度） 每次接受一个ACK，ConWIn大小加1 每当过了一个往返时延RTT，ConWin大小直接翻倍 当ConWin达到预先设置的阈值ssthresh时或者发生丢包事件，进入拥塞避免算法 拥塞避免算法 收到ACK时，线性增长ConWin 当网络出现丢包（收到重复的ACK或者超时）时，更新阈值ssthresh为原来的一半 快重传算法 快速重传算法要求接收方收到一个失序的报文段之后就立即发出重复确认而不需要等到自己发送数据时捎带确认，一旦收到三个重复确认的ACK就立即重传而不需要等待超时计时器到期。 快恢复算法 配合快重传算法，当发送方收到连续三个重复的ACK，就执行乘法减小算法，把ssthresh门限减半，但是接下去并不执行满开始算法。 考虑网络拥塞就不会收到好几个重复的确认，发送方认为网络没有出现拥塞，此时不执行慢开始算法，而是执行拥塞避免算法。 注意：在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用。 参考文献TCP流量控制、拥塞控制 TCP可靠传输原理 TCP 拥塞控制算法 《计算机网络-自顶向下方法（原书第四版）》]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java的多态机制]]></title>
    <url>%2F2019%2F07%2F13%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E7%9A%84%E5%A4%9A%E6%80%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Java多态原理和使用多态的概念面向对象有三大特性，继承，封装，多态。 多态表示指在编程中不能确定引用对象指向的具体类型或是方法调用，而要在程序运行时才能确定。 该引用变量的方法调用到底是那个类实现的方法，必须在程序运行期间才能确定，这样不用修改程序源码就可以让引用变量动态的绑定到不同的类实现上从而导致该引用调用的方法随之改变。 不修改程序代码就可以改变程序运行时绑定的具体代码，程序可以选择多个运行状态，这就是面向对象语言的多态性。 多态主要分为编译时的多态和运行时的多态。 一个典型的多态问题相关类 123456789101112131415161718class A&#123; public String show(D obj)&#123; return ("A and D"); &#125; public String show(A obj)&#123; return ("A and A"); &#125; &#125;class B extends A&#123; public String show(B obj)&#123; return ("B and B"); &#125; public String show(A obj)&#123; return ("B and A"); &#125; &#125;class C extends B&#123;&#125; class D extends B&#123;&#125; 问题： 1234567891011121314 A a1 = new A(); A a2 = new B(); B b = new B(); C c = new C(); D d = new D(); System.out.println(a1.show(b)); ① System.out.println(a1.show(c)); ② System.out.println(a1.show(d)); ③ System.out.println(a2.show(b)); ④ System.out.println(a2.show(c)); ⑤ System.out.println(a2.show(d)); ⑥ System.out.println(b.show(b)); ⑦ System.out.println(b.show(c)); ⑧ System.out.println(b.show(d)); ⑨ 答案如下： A and A A and A A and D B and A B and A A and D B and B B and B A and D 一般来说，方法调用的优先级如下： this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O). 比如说4，因为a1指向的是一个B的对象，所以B重写了A中show(A obj)方法，所以实际会调用B中show(A obj)方法。 重写和重载运行时的多态性时面向对象程序设计语言设计代码宠用的一个最强大的特性，动态性的概念可以描述为“一个接口，多个方法”。 Java实现运行时多态性的基础是动态方法调度，是一种在运行时而不是在编译期调用重载方法的机制。 方法的重写(Overriding)和方法的重载(Overloading)是Java多态性的不同表现。 Overriding 是父类和子类之间多态性的一种表现，重写是指子类中定义的某个方法与其父类有相同的名称和参数，我们说该方法被重写(overrding)。子类对象使用该方法时，将调用子类中的定义，对于父类的定义如同被屏蔽了。 Overloading是指在一个类中定义了多个同名的方法，或者有不同的参数个数，或者有不同的参数类型，则称为方法的重载。Overloaded的方法还可以改变返回值的类型。 多态的缺陷向上转型是有局限性的：在向上转型中，可以调用的方法就是父类中有的，但是子类中没有的方法，和子类中重写父类的方法。 多态代码的第一个缺陷 1234567891011public class Instrument &#123; private void play() &#123; System.out.println("Instrument play"); &#125; public static void main(String[] args) &#123; Instrument ins = new Piano(); ins.play(); &#125;&#125;class Piano extends Instrument &#123; public void play() &#123; System.out.println("Piano play"); &#125;&#125; 12//outputIntrument play 这里子类对象实例化后赋值给父类对象，这里就是向上转型，那么根据向上转型的特点，ins可以调用父类中有，而子类没有的方法和子类重写的方法. 但是这里父类是private 方法，而private方法默认为final方法，final类方法不可以被继承，这旧说明Piano类中的play方法是一个全新的方法，所以ins不能调用子类的play()方法。 第二个缺陷：域和静态方法， 域和静态方法和多态无关。 123456789101112131415161718192021222324class Super &#123; public int field = 0; public int getField() &#123; return field; &#125; &#125; class Sub extends Super &#123; public int field = 1; public int getField() &#123; return field; &#125; public int getSuperField() &#123; return super.field; &#125; &#125; public class FieldAccess &#123; public static void main(String[] args) &#123; Super sup = new Sub(); // Upcast System.out.println("sup.field = " + sup.field + ", sup.getField() = " + sup.getField()); Sub sub = new Sub(); System.out.println("sub.field = " + sub.field + ", sub.getField() = " + sub.getField() + ", sub.getSuperField() = " + sub.getSuperField()); &#125; &#125; 123// Output: sup.field = 0, sup.getField() = 1 sub.field = 1, sub.getField() = 1, sub.getSuperField() = 0 这段代表表明了当父类和子类拥有名称相同的域时，在向上转型时，子类的域和父类的域是不存在多态的。此外，静态方法也和多态无关。 Java多态的实现原理多态允许具体访问实现方法的动态绑定，Java对于动态绑定的实现主要依赖于方法表，通过继承和接口的多态实现有所不同。 继承：在执行某个方法的时候，在方法区找到该类的方法表，确认该方法在方法表中的偏移量，找到该方法后如果被重写则直接调用，否则认为没有重写父类该方法，这时候按照继承关系搜索父类的方法表中该偏移量对应的方法。 接口：Java允许一个类实现多个接口，从某种意义上相当于多继承，这样同一个接口的方法在不同类的方法表中的位置可能就不一样了。要通过搜索完整的方法表。 在JVM中： 当程序运行需要某个类的时候，类加载器会将对应的class文件加载到JVM中，并且在方法区建立该类的类型信息（包括方法代码，类变量，成员变量和方法表）。 方法表是实现动态调用的核心，为了优化对象调用方法的速度，方法区的类型信息会增加一个指针，指向记录该类方法的方法表。 Java的方法调用方式 Java方法调用有两类 静态方法调用是指对类的静态方法的调用，是静态绑定的。而动态方法调用需要有方法调用所作用的对象，是动态绑定的。 类调用：在编译时就已经确定号具体调用方法的情况。 实例调用：则是在调用的时候才确定具体的调用方法，这就是动态绑定，也是多态要解决的核心问题。 参考文献 深入理解java多态性 面向对象编程三大特性——封装、继承、多态 理解 Java 的三大特性之多态 Java技术——多态的实现原理 多态在JVM中的实现——invokevirtual与invokespecial]]></content>
      <categories>
        <category>面向对象基础</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器输入URL到获取网页的过程]]></title>
    <url>%2F2019%2F07%2F11%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5URL%E5%88%B0%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[浏览器输入URL到获取网页的过程 上面这张图大致描述了浏览器输入URL之后发生了什么。下面梳理一下详细的流程。 在条件是： 一个Chrome浏览器 一台Linux服务器 发起HTML请求 不考虑缓存和优化 采用HTTP/1.1+TLS/1.2+TCP协议 从浏览器输入URL地址URL也叫做统一资源定位符，描述了特定服务器上某个资源特定的位置，URL包括三个部分： scheme描述访问资源使用的协议 服务器的因特网地址 其余部分指定了web服务器的某个资源 一个有效的URL 1http://video.google.com.uk:80/videoplay?docid=-7246927612831078230&amp;hl=en#00h02m30s 上述网址分解为： 传输协议：http，类似还有https,ftp,etc 主机或者主机名：video.google.com.uk 子域名是：video 域名是google.co.uk 顶级域名：uk 二级域名：com.uk 端口号：80（http协议的默认端口） 路径：表示web服务器上一个资源的位置 查询过程： 首先会查询浏览器的缓存，浏览器会存储一定时间内的DNS记录 如果没有找到，操作系统缓存中查询； 路由器也会由DNS记录，继续在路由器缓存中查询； ISP互联网供应商中查询，这里是接入internet的中继站 最后在DNS系统上查找； DNS解析过程DNS采用迭代查询和递归查询两种方式，因为IP地址难以记忆，所以域名帮助我们记住网址，域名实际上并不能找到服务器的位置，而是要将域名通过DNS服务器解析为ip地址之后再去确定服务器的位置。 首先浏览器像本地DNS服务器发送请求，如果本地的DNS地址未查询到，需要采用递归和迭代的方式依次向根域名服务器，顶级域名服务器，权威域名服务器发送查询请求，知道找到一个或者一组ip地址，返回给浏览器。 DNS本身的传输协议是UDP协议，但是每一次迭代和递归查找是很耗时的，所以DNS存在这多级缓存， 缓存分为：浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。 DNS负载均衡DNS每一次不一定会返回一个同一个服务器的地址，DNS可以返回一个合适的机器的IP，根据每台机器的负载量，机器的物理位置等合理分配。CDN技术就是利用DNS的重定向技术返回一个离用户最近的服务器。 TCP连接建立TCP连接，经典的三次握手过程。 TCP是一个端到端的可靠的面向连接的协议，所以HTTP基于传输层协议不用担心数据的传输问题。 发起HTTP请求请求方法： GET:获取资源 POST:传输实体主体 HEAD:获取报文首部 PUT:传输文件 DELETE:删除文件 OPTIONS:询问支持的方法 TRACE:追踪路径 建立安全的加密信道之后，浏览器开始发送http请求，请求报文由请求行，请求头，空行，实体组成。请求头由 通用首部，请求首部，实体首部，扩展首部组成。 返回HTTP响应接受响应结果，详细的HTTP状态码如下： HTTP状态码详解 最后到内容到浏览器，浏览器开始解析html和加载渲染。 参考文献浏览器输入 URL 后发生了什么？ 从输入URL到页面加载发生了什么 浏览器中输入url后发生了什么 从面试题“输入URL…发生了什么?”学到的]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>网络基础</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次挥手和四次挥手]]></title>
    <url>%2F2019%2F07%2F04%2FTCP%E4%B8%89%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP三次握手和四次挥手《图解HTTP》 简单示意图： 客户端-发送带有SYN标志的数据包，一次握手–服务端 服务端-发送带有SYN/ACK标志的数据包-二次握手-客户端 客户端-发送带有ACK标志的数据包-三次握手-服务端 三次握手的目的三次握手最重要的目的就是双方确认自己与对方发送与接受是正常的。 第一次握手：Client什么都不能确认；Server确认对方发送正常。 第二次握手：Client确认自己的发送，接受正常，对方发送接收正常；server确认了自己接收正常，对方发送正常； 第三次握手：Client确认了自己发送，接收正常，对方发送接收正常；Server确认了自己发送，接收正常，对方发送，接收正常。 为什么要传回SYN接收端传回发送端的SYN是为了告诉发送端，我接收到的信息确实就是你发送的信号。 传了SYN，为啥还要传ACK双方通信无误必须是两者相互发送信息都无误，传了SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要ACK信号来验证。 断开一个TCP连接需要”四次挥手”： 客户端：发送一个FIN，用来关闭客户端到服务器的数据传送 服务器: 收到一个FIN，发回一个ACK,确认序号为接收到的序号加1，和SYN一样，一个FIN将占用一个序号 服务器： 关闭与客户端的连接，发送一个FIN给客户端 客户端： 发挥ACK确认报文，将确认序号设置为收到的序号加1 为什么客户端还要等待2MSL(MSL:报文最大生存时间)第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK可能丢失，这样服务器 会重新发送一次，这样客户端在2MSL的时间内可以收到重传的报文，接着给出回应报文，并且重启2MSL计时器。 第二，防止类似和”三次握手”中提到的”已经失效的连接请求报文段“出现在本连接中，客户端发送完最后一个确认报文后，在这2MSL的时间内，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。 为什么建立连接是三次回收，关闭连接确是四次挥手？建立连接的时候，服务器在LISTEN状态下，收到建立连接请求的SYN报文之后，把ACK和SYN放在一个报文里发送给客户端。 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据但是还是能接收到数据，而自己也未必全部数据都发送给对方，所以己方可以立即关闭，也可以发送一些数据对对方后，再发送FIN报文给对方来表示同意现在关闭连接。因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 如果已经建立了连接，但是客户端突然出现了故障该怎么办？TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。]]></content>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网路体系结构概述]]></title>
    <url>%2F2019%2F07%2F02%2F%E7%BD%91%E8%B7%AF%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[计算机网络体系结构概述主机间的通信方式客户端(C/S):客户是服务请求方，服务器是服务提供方。 对等(P2P)：不区分客户和服务器，每个既可以充当客户端，也可以充当服务器。 电路交换和分组交换1电路交换：用于电话通信系统，两个用户在通信之前需要建立专用的物理链路，并且通信过程中始终需要占据该链路。对链路利用率很低。 2分组交换：分组都有首部和尾部，包含源地址和目的地址等控制信息（五元组:源IP地址、目的IP地址、协议号、源端口、目的端口）。 时延总时延=排队时延 + 处理时延 + 传输时延 + 传播时延 五层协议应用层：为特定应用程序提供数据传输服务，例如HTTP，DNS等协议。 传输层：为进程提供通用数据传输服务。例如TCP，UDP. 网络层：为主机提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据封装为分组。 数据链路层：网络层针对的还是主机之间的服务，而主机之间有很多链路，数据链路层把网络层传下来的分组封装成帧。 物理层：物理层的作用是尽可能地屏蔽传输媒体和通信手段之间的差异。 TCP/IP四层相当于传统五层协议中的数据链路层和物理层合并为网络接口层。 网络体系概述常见面试题1.OSI与TCP/IP各层的结构和功能，都有那些协议? 结合互联网情况，自上而下 介绍各层作用。 1应用层应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程之间的通信和交互规则。不同的网络应用需要不同应用层协议，互联网中应用层协议有：DNS，HTTP，SMTP等等，应用层交互的数据单元称为报文。 域名系统： 域名系统简称DNS,是因特网上的一项核心服务，作为一个将域名和ip地址相互映射的分布式的数据库，人们能够更方便的访问互联网，不需要记住ip地址。 HTTP协议 超文本传输协议是互联网上应用最为广泛的一种网络协议，所有的万维网文件都必须遵守这个标准，设计HTTP最初的目的就是提供一种发布和接受html页面的方法。 2传输层传输层的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。通用的意思就是不针对某一个特定的网络应用，而是多种应用可以使用同一个传输层服务。一台主机可以运行多个线程，所以运输层有复用和分用的功能。 传输层协议包括： 传输控制协议TCP(Transmission Control Protocol)–提供面向连接的，可靠的数据传输服务。 用户数据协议UDP(User Datagram Protocol)–提供无连接的，尽最大努力的数据传输服务。 UDP： 无连接的 不保证可靠交付 面向报文 没有拥塞控制, 一对一，一对多，多对一的交换通信 UDP的首部开销小，8个字节，TCP20个字节 TCP： 面向连接的 每一条TCP连接只能有两个端点，每一条TCP连接都是点对点的 TCP提供可靠交付的服务，通过TCP连接传输的数据，无差错，不丢失，不重复，并且按序到达。 TCP提供全双工的通信。TCP允许通信双方在任何时候都可以发送数据，TCP连接的两端设有发送缓存和结构缓存 来临时存放双方通信的数据。 面向字节流，TCP把应用程序里的数据看作一串无结构的字节流。 3网络层在计算机网络中通信的两个计算机之间会有很多数据链路和通信子网，网络层的任务就是选择合适的网间路由和交换节点，确保数据能够及时传送。发送数据时，网络层把运输层产生的报文段和用户数据封装成分组和包进行传送。 网络层的协议主要包括ip协议和许多路由选择协议。 4数据链路层用于两台主机之间的数据传输，总是在一段段的链路上传送的专门的链路层协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装程帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。 5物理层在物理层上传送的数据单位是比特，实现了相邻计算机结点之间比特流的透明传输，尽可能屏蔽掉实际电路传送后比特流没有发生变化。]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM运行时数据区域划分]]></title>
    <url>%2F2019%2F06%2F10%2FJVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86%2F</url>
    <content type="text"><![CDATA[JVM运行时数据区域1.程序计数器程序计数器的定义：当前线程所执行的字节码的行号指示器。通过改变计数器的值选取下一条需要执行的字节码指令。分支，循环，跳转，异常处理，线程恢复等基础功能。在虚拟机的概念模型里（仅仅是概念模型，各种虚拟机可能会通过一些更加高效的方式来实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条要执行的字节码指令。 当前线程所执行的字节码的行号指示器：程序计数器中只存储当前线程执行程序的行号，一个类指针的数据结构 java虚拟机的多线程通过线程轮流切换并且分配处理器执行时间的方式来实现的。所以线程为了能在切换后恢复正确的执行位置，每个线程都需要有一个独立的程序计数器。各个线程之间计数器互不影响，独立存储，这样的现在我们称其内存区域为“线程私有”的内存。 因此，程序计数器是线程私有的。 执行状态： 当一个线程正在执行一个Java方法的时候，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果执行是Native方法，那么计数器值为空。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutMemoryError的区域。 2.Java虚拟机栈虚拟机栈描述的是java方法执行的内存模型。每个方法在执行的同时都会创建出一个栈帧用于存储局部变量表，操作数栈，动态链接，方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧从入栈到出栈的过程。 局部变量表：存放了编译器可知的各种数据类型(boolean,byte,char,short,int, long ,float, double)，对象引用。 3.本地方法栈本地方法栈与虚拟机栈的作用是十分相似的，区别在于本地方法栈为虚拟机使用的native方法服务。 4.Java堆java堆的定义：java堆是被所有线程共享的一块内存区域，虚拟机启动时创建，唯一目的就是存放对象实例，几乎所有的对象 实例都在这里创建。 Java堆是垃圾收集器管理的主要区域。 5.方法区与堆一样，方法区是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。 6.运行时常量池方法区的一部分，Class文件除了有类的模板，字段，方法，接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2019%2F06%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之单例模式单例模式(Singleton Pattern)是一个比较简单的模式，定义如下: Ensure a class has only one instance, and provide a global point of access to it. 确保一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。 以下是单例模式的几种写法： 懒汉式–线程不安全1234567891011public class Singleton&#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 代码简洁明了，使用了懒加载模式，但是在多个线程并行调用getInstance()的时候，会创建多个实例，在多线程下不能正常工作。 懒汉式–线程安全为了解决上述问题，最简单的方法就是将整个getInstance()方法设为同步(synchronized). 123456public static synchronized Singleton getInstance()&#123; if(instance == null) &#123; instance = new Singleton(); &#125; return instance;&#125; 这种方式做到了线程安全，但是并不高效，任何时候都只能有一个线程调用getInstance()方法，同步操作只有第一次调用时才需要。于是有人引出了双重检验锁。 双重检验锁双重检验锁(double checked locking pattern)是一种使用同步块加锁的方法。我们称其为双重检验锁，因为会有两次检查instance == null，一次是在同步块外，一次是在同步块内。 为什么要检查两次，因为可能会有多个线程一起进入同步块的if，如果不进行二次检验就会生成多个实例 12345678910public static Singleton getSingleton()&#123; if(instance == null)&#123; synchronized (Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance;&#125; 这段代码看上去完美，但是还是有问题，主要在于instance = new Singleton()并非是一个原子操作，事实上在JVM中这句话大概做了3件事情： 给instance分配内存 调用Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间 但是在JVM的即时编译器中存在指令重排序的优化，即上述第二步和第三步的顺序是不能保证的，最终执行顺序可能是1-2-3也可能是1-3-2。如果是后者，则在3执行完毕，2未执行之前被线程二抢占，这时instance 已经是非null(没有初始化)，线程2会直接返回instance，然后使用时报错。 我们只需要将instance变量声明为volatile 12345678910111213141516public class Singleton&#123; //声明成volatile private volatile static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized(Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; volatile关键字的作用： 保证变量在内存中的可见性 保证程序执行的顺序，volatile关键字禁止指令重排 这里其实用到的是volatile关键字的有序性，确保JVM执行时不会进行指令重排。 饿汉式–static final field直接将单例的实例声明成static和final变量，这样在类第一次加载时就在内存中初始化，所以实例本身是线程安全的。 123456789public class Singleton&#123; //类加载时就初始化 private static final Singleton instance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; 这种写法的缺点在于单例会在加载类一开始就被初始化，这导致了饿汉式在某些场景中无法使用，比如Singleton实例的创建依赖参数或者配置文件的，在getInstance()之前必须调用某个方法设置参数给它，这样这种单例写法无效了。 静态内部类 static nested class这种方法是《effective Java》上所推荐的。 12345678910public class Singleton&#123; private static class SingletonHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种写法使用JVM本身的机制来保证了线程安全的问题，由于SingletonHolder是私有的，除了getInstance()方法没有办法访问到他，同时读取实例的时候不会进行同步，没有性能缺陷，不依赖于JDK版本。 枚举 Enum用枚举写单例实在太简单了！这也是它最大的优点。下面这段代码就是声明枚举实例的通常做法。 123public enum EasySingleton&#123; INSTANCE;&#125; 我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。 几种创建方式的总结一般来说，单例模式有五种线程安全的写法：懒汉，饿汉，双重检验锁，静态内部类，枚举。 单例模式的使用场景在以下场景适合单例模式： 有频繁实例化然后销毁的情况。 创建对象耗时多或者消耗资源多而又使用频繁。 频繁访问IO资源的对象，例如数据库连接池或者访问本地文件。 比如说： 网站在线人数统计 这其实就是一个全局计数器，所有用户在同一时刻获取的在线人数数量都是一致的，这里包含分布式场景。下面代码简单实现一个计数器： 123456789101112131415161718192021public class Counter&#123; private static class CounterHolder&#123; private static final Counter counter = new Counter(); &#125; private Counter()&#123; System.out.println("init..."); &#125; private static final Counter getInstance()&#123; return CounterHolder.counter; &#125; private AtomicLong online = new AtomicLong(); public long getOnline()&#123; return online.get(); &#125; public long add()&#123; return online.increasementAndGet(); &#125;&#125; 配置文件访问类 项目种经常需要一些环境相关的配置文件，比如短信通知相关，邮件相关。比如使用Spring，可以使用@PropertySource注解实现，默认就是单例模式，不用单例的话，每次都要new对象，读取配置文件。 123456789101112131415161718192021222324252627282930313233343536public class SingleProperty&#123; private static Properties prop; private static class SinglePropertyHolder&#123; private static final SingleProperty singleProperty = new SingleProperty(); &#125; /** * config.properties 内容是 test.name=kite */ private SingleProperty()&#123; System.out.println("构造函数执行"); prop = new Properties(); InputStream stream = SingleProperty.class.getClassLoader() .getResourceAsStream("config.properties"); try &#123; prop.load(new InputStreamReader(stream, "utf-8")); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static SingleProperty getInstance()&#123; return SinglePropertyHolder.singleProperty; &#125; public String getName()&#123; return prop.get("test.name").toString(); &#125; public static void main(String[] args)&#123; SingleProperty singleProperty = SingleProperty.getInstance(); System.out.println(singleProperty.getName()); &#125;&#125; 数据库连接池的实现 做池化的原因就是新建连接十分耗时，一般做法是在应用内维护一个连接池，这样当任务进来时，如果有空闲连接可以直接拿来用，省去了初始化的开销。所以单例模式正好实现一个应用内只有一个线程池，所有的连接任务都需要从连接池里获取连接。 参考文献如何正确地写出单例模式 单例模式的使用场景]]></content>
      <categories>
        <category>面向对象基础</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之AOF持久化]]></title>
    <url>%2F2019%2F05%2F30%2FRedis%E4%B9%8BAOF%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis之AOF持久化Redis提供AOF(Append Only Files)持久化功能，RDB持久化通过保存数据库中键值对来记录数据库的状态，AOF持久化通过保存Redis服务器所执行的写命令来记录数据库状态。 Redis.conf配置 123appendfsync yes appendfsync always #每次有数据修改发生时都会写入AOF文件。appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。 AOF持久化的实现具体实现可以分为命令追加(append)，文件写入，文件同步三个步骤 命令追加当Redis服务器打开了AOF持久化时，服务器在执行完一个写命令后，会以协议的格式将被执行的写命令追加到服务器状态的aof_buf缓冲区末尾。 AOF文件的写入和同步使用 AOF 持久化需要设置同步选项，从而确保写命令什么时候会同步到磁盘文件上。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： 选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能，每个事件循环都要将aof_buf中的内容写入到AOF文件中，但是也是最安全的，因为即使Redis宕机也只会丢失一个事件循环的所有命令数据。 everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 AOF重写随着保存的命令越来越多，AOF文件中的内容也越来越多，而且AOF文件中的命令很有可能是冗余的，而且数据还原的时间就会越长，这时候就需要重写AOF文件来减小AOF文件的体积。 AOF文件重写的实现服务器为了保存数据库的状态，其实实际上不是去读取AOF文件来实现重写，而是直接读取数据库的状态，比如读取List的值并且用一条RPUSH list的命令行代替保存在AOF文件中。 AOF后台重写在执行BGREWRITEAOF命令时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建AOF文件期间，记录服务器所有的写命令，当子进程完成创建后，服务器会将重写缓冲区中所有的内容追加到AOF的文件末尾。最后服务器会用新的AOF文件替换旧的AOF文件 Redis4.0新功能简介：RDB-AOF混合持久化Redis用户常常会在RDB和AOF之间陷入两难： RDB持久化能够快速的恢复数据，但是在服务器停机时会丢失大量的数据； AOF持久化能够有效提高数据的安全性，但是在存储和恢复方面耗费大量的时间； Redis 4.0 推出了一个能够“鱼和熊掌兼得”的持久化方案 —— RDB-AOF 混合持久化： 这种持久化能够通过 AOF 重写操作创建出一个同时包含 RDB 数据和 AOF 数据的 AOF 文件， 其中 RDB 数据位于 AOF 文件的开头， 它们储存了服务器开始执行重写操作时的数据库状态： 至于那些在重写操作执行之后执行的 Redis 命令， 则会继续以 AOF 格式追加到 AOF 文件的末尾， 也即是 RDB 数据之后。 参考文献Redis持久化RDB和AOF优缺点是什么？ AOF和RDB持久化 Redis 4.0 新功能简介：RDB-AOF 混合持久化]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP中的Cookie和Session]]></title>
    <url>%2F2019%2F05%2F27%2FHTTP%E4%B8%AD%E7%9A%84Cookie%E5%92%8CSession%2F</url>
    <content type="text"><![CDATA[Cookie的机制与安全什么是Cookie？ HTTP Cookie（也叫Web Cookie或浏览器Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。 cookie，指网站为了辨别用户身份而储存在用户本地终端上的数据。cookie 本质上是 HTTP 的一个内容（请求头）。 在前端工作中，可以这么理解 cookie： cookie 是浏览器访问服务器后，服务器传给客户端的一段数据。 浏览器将 cookie 保存下来，一般情况下不会删除。 浏览器每次访问返回 cookie 的服务器时，都会在请求头（请求的第二部分）中带入这段 cookie Cookie的作用 会话状态管理（如用户登录状态，购物车，游戏分数或者其它需要） 个性化设置（用户自定义设置，主题） 浏览器行为跟踪（跟踪分析用户行为） Cookie在浏览器和服务器之间的交流过程接下来，以client指代客户端，server指代服务端，说明一个 cookie 的整个作用机制： 产生cookie:client第一次访问server，server 在响应头中设置一个 cookie 返回给 client，cookie 的内容为要保存的数据。 保存 cookie：client 在接收到 server 返回的 cookie 后，将 cookie 保存下来,并给cookie一个有效期，过了有效期，cookie 就会失效。 传递 cookie：client 再次访问 server 将会在请求头中带上保存的 cookie，将 cookie 传递到 server。 解析 cookie：server 得到 client 传递的 cookie 之后，会解析 cookie，然后将相应的信息返回给 client。在 cookie 没有失效之前，cookie 的使用都是围绕2,3,4三部分来进行的，第1步一般只需要进行一次。 Cookie存在的问题 cookie 基于浏览器本地存储数据，因此，只有在保存了 cookie 的那个浏览器上能够使用该 cookie。同一设备不同浏览器之间，cookie 不通用。 cookie 的存储大小有限制： 4KB 左右。 cookie 存在C盘的一个文件中，不同浏览器存储路劲不一样。 cookie 是可以被用户手动修改的。 cookie 的有效期：默认有效期20分钟左右。可以通过后端强制设置有效期，如自动登录时间。 cookie 的同源策略：cookie 同样也有同源策略，不过与 ajax 略微不用。ajax 需要完全同源，而 cookie 只需要同一父级域名即可。 比如： 请求 qq.com 下的资源时，会带上 qq.com 对应的 cookie，不会带上 baidu.com 的 cookie； 请求 v.qq.com 下的资源时，浏览器不仅会带上 v.qq.com 的 cookie，还会带上 qq.com 的cookie。在这里，qq.com 就是 v.qq.com 的父级域名。 需要特别注意的一点是：在浏览器的认知中，www.qq.com和qq.com是两个不同的域名。因此，www.qq.com 不是 v.qq.com 的父域名，qq.com才是。 由于 cookie 是明文保存在客户端的数据，可能会被客户端修改，存在信息泄露的风险，所以，需要一种比 cookie 更加安全的存储方式来存储数据。session 就是解决安全问题的方法。 Cookie: HttpOnly标记为HttpOnly的Cookie不能被JavaScript脚本调用，跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 Cookie的安全隐患Cookie提供了一种手段使得HTTP请求附加当前的状态，网站也是靠Cookie标识用户登录状态的： 用户提交用户名和密码的表单，通常是一个POST HTTP请求。 服务器验证用户名与密码，如果合法则返回200（OK）并设置Set-Cookie为authed=true。 浏览器存储该Cookie。 浏览器发送请求时，设置Cookie字段为authed=true。 服务器收到第二次请求，从Cookie字段得知该用户已经登录。 按照已登录用户的权限来处理此次请求。 但是不仅浏览器可以发送HTTP请求，许多HTTP客户端软件也可以发送，可以设置任何头字段，假如我们直接设置Cookie字段为authed=true并发送该HTTP请求， 服务器岂不是被欺骗了？这种攻击非常容易，Cookie是可以被篡改的！ Cookie的防篡改机制服务器可以为每个Cookie项生成签名，由于用户篡改Cookie后无法生成对应的签名， 服务器便可以得知用户对Cookie进行了篡改。一个简单的校验过程可能是这样的： 在服务器中配置一个不为人知的字符串（我们叫它Secret），比如：x$sfz32。 当服务器需要设置Cookie时（比如authed=false），不仅设置authed的值为false， 在值的后面进一步设置一个签名，最终设置的Cookie是authed=false|6hTiBl7lVpd1P。 签名6hTiBl7lVpd1P是这样生成的：Hash(&#39;x$sfz32&#39;+&#39;false&#39;)。 要设置的值与Secret相加再取哈希。 用户收到HTTP响应并发现头字段Set-Cookie: authed=false|6hTiBl7lVpd1P。 用户在发送HTTP请求时，篡改了authed值，设置头字段Cookie: authed=true|???。 因为用户不知道Secret，无法生成签名，只能随便填一个。 服务器收到HTTP请求，发现Cookie: authed=true|???。服务器开始进行校验： Hash(&#39;true&#39;+&#39;x$sfz32&#39;)，便会发现用户提供的签名不正确。 通过给Cookie添加签名，使得服务器得以知道Cookie被篡改。 因为Cookie是明文传输的， 只要服务器设置过一次authed=true|xxxx我不就知道true的签名是xxxx了么， 以后就可以用这个签名来欺骗服务器了。因此Cookie中最好不要放敏感数据。 一般来讲Cookie中只会放一个Session Id，而Session存储在服务器端。 Session的机制和安全Session的定义 在计算机科学领域来说，尤其是在网络领域，会话（session）是一种持久网络协议，在用户（或用户代理）端和服务器端之间创建关联，从而起到交换数据包的作用机制，session在网络协议（例如telnet或FTP）中是非常重要的部分。 个人理解： session 是一种在服务器端保存数据的机制。服务器通过读取浏览器发送的 cookie 和 服务器端的 session 来交换数据。 不同于 cookie，session保存在服务器端，不同的语言保存方式不一样： java，保存于服务器内存中，重启服务器，session 消失 php，保存于服务器文件中，重启服务器，session 依然存在 nodejs，保存于服务器内存中，重启服务器，sessino 消失 Session的作用和Cookie大致相同，但是最大的不同点在于两者实现的安全性和实现方式。 Session的实现依然将客户端称为 client，服务端成为 server。 1.产生 sessionID：session 是基于 cookie 的一种方案，所以，首先要产生 cookie。client 第一次访问 server，server 生成一个随机数，命名为 sessionID，并将其放在响应头里，以 cookie 的形式返回给 client，client 以处理其他 cookie 的方式处理这段 cookie。大概是这样：cookie：sessionID=135165432165 2.保存 sessionID： server 将要保存的数据保存在相对应的 sessionID 之下，再将 sessionID 保存到服务器端的特定的保存 session 的内存中（如 一个叫 session 的哈希表） 3.使用 session： client 再次访问 server，会带上首次访问时获得的 值为 sessionID 的cookie，server 读取 cookie 中的 sessionID，根据 sessionID 到保存 session 的内存寻找与 sessionID 匹配的数据，若寻找成功就将数据返回给 client。 Session 与 cookie 的区别 session 在服务器端，cookie 在客户端。 session 用户无法查看和修改，cookie 用户可以查看修改。 session 和 cookie 的存储容量不同。 session 的实现依赖于 sessionID，而 sessionID 又存储在 cookie 上，所以，可以这么说：session 是基于 cookie 实现的一种数据存储方式。 Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 参考文献《图解HTTP》 日 上野宣 详解cookie、session和HTTP缓存 HTTP cookies 详解 COOKIE和SESSION有什么区别？]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP中的方法]]></title>
    <url>%2F2019%2F05%2F26%2FHTTP%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[HTTP中的方法GET:获取资源GET方法用来请求访问已被URI识别的资源。指定资源经服务器端解析后返回响应内容。 POST：传输实体主体POST方法用来传输实体的主体 虽然用GET方法也可以传输实体的主体，但是一般不用GET方法。 PUT：传输文件用来传输文件，就像FTP协议的文件上传。 HEAD：获取报文首部HEAD 方法和 GET 方法一样， 只是不返回报文主体部分。 用于确认URI 的有效性及资源更新的日期时间等 DELETE: 删除文件DELETE 方法用来删除文件， 是与 PUT 相反的方法。 DELETE 方法按请求 URI 删除指定的资源 。 OPTIONS：询问支持的方法OPTIONS方法用来查询针对请求URI指定的资源支持的方法 TRACES：追踪路径TRACE方法是让web服务器端将之前的请求通信环回给客户端的方法。 Connect：要求用隧道协议代理链接CONNECT 方法要求在与代理服务器通信时建立隧道， 实现用隧道协议进行 TCP 通信。 主要使用 SSL（Secure Sockets Layer， 安全套接层） 和 TLS（Transport Layer Security， 传输层安全） 协议把通信内容加 密后经网络隧道传输。 HTTP/1.0和HTTP/1.1支持的方法 方法 说明 支持的 HTTP 协议版本 GET 获取资源 1.0、 1.1 POST 传输实体主体 1.0、 1.1 PUT 传输文件 1.0、 1.1 HEAD 获得报文首部 1.0、 1.1 DELETE 删除文件 1.0、 1.1 OPTIONS 询问支持的方法 1.1 TRACE 追踪路径 1.1 CONNECT 要求用隧道协议连接代理 1.1 LINK 建立和资源之间的联系 1.0 UNLINE 断开连接关系 1.0 GET和POST对比作用GET用于获取资源，而POST用于传输实体主体。 参数GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。 因为GET是通过URL提交数据的，所以GET可提交的数据量就和URL的长度有关。HTTP没有限制URL长度，但浏览器会限制URL长度 而POST方法则是把提交的数据放置在HTTP包的包体中。 连接对于GET方式请求，浏览器会把http header和data一并发送出去，服务器响应200。 对于POST方式请求，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 OK。但是不是所有的浏览器都会发送两次包，比如火狐。 安全安全的HTTP方法不会改变服务器状态，它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 幂等性GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的： 1234GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1Copy to clipboardErrorCopied POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录： 123POST /add_row HTTP/1.1 -&gt; Adds a 1nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 2nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 3rd rowCopy to clipboardErrorCopied DELETE /idX/delete HTTP/1.1 是幂等的，即使不同的请求接收到的状态码不一样： 123DELETE /idX/delete HTTP/1.1 -&gt; Returns 200 if idX existsDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 as it just got deletedDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 可缓存如果要对响应进行缓存，需要满足以下条件： 请求报文的HTTP方法是可以缓存的，包括GET和HEAD，但是PUT和DELELTE不可缓存，POST在多数情况下不可缓存。 响应报文的状态码时刻缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的Cache-Control首部字段没有指定不可缓存。 XMLHttpRequest为了阐述POST和GET的另一个区别，需要先了解XMLHttpRequest: XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。 参考文献《图解HTTP》日，上野宣. 9%的人理解错 HTTP 中 GET 与 POST 的区别 HTTP中Get与Post的区别]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP状态码详解]]></title>
    <url>%2F2019%2F05%2F23%2FHTTP%E7%8A%B6%E6%80%81%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[HTTP状态码HTTP状态码类别 类别 原因短语 1XX Informational（信息性状态码) 接受的请求正在处理 2XX Success(成功性状态码) 请求正常处理完毕 3XX Redirection(重定向状态码) 需要进行附加操作以完成请求 4XX Client Error(客户端错误状态码) 服务器无法处理请求 5XX Server Error(服务器错误状态码) 服务器处理请求出错 2XX成功2xx的响应结果表示请求被正常处理。 200OK表示客户端发来的请求被服务端正常处理。 例如GET方法对应请求资源的实体作为响应返回，HEAD方法对应请求资源的实体首部不随报文主体作为响应返回。 204 No Content表示服务器接受的请求已经成功处理，但是在返回的响应报文中不包含实体的主体部分。也不允许返回任何实体主体。 1&#123;status: 0, message:""&#125; //status 0代表成功, 非零的时候, message中包含出错信息. 所以有一些服务, 只是返回成功与否的时候, 可以尝试使用HTTP的状态码来作为返回信息, 而省掉多余的数据传输, 比如REST中的DELETE和上述Ajax请求. 206 Partial Content该状态码表示客户端进行了范围请求，而服务器成功执行了这部分GET请求。响应报文中包含Content-Range指定范围的实体内容。 3XX重定向3XX表示浏览器需要执行某些特殊处理以正确处理请求。 301 Moved Permanently表示请求资源被分配了新的URI，这种对搜索引擎是友好的，一旦网页a永久定位到网页b，那么使用301重定向后，搜索引擎会将a的累积权重传到网页b。(例如Google会传大部分权重) 302 Found临时性重定向，表示该资源已被重新分配了URI，希望这次能够用新的URI访问。 303 See Other表示请求对应的资源存在另一个URI，应该使用GET方法定向获取请求资源。 303主要目的是允许POST请求的响应将客户端定位到某个资源上。比如说，在文件上传完成后让客户端自动重定向到一个上传成功的结果页面。 304 Not Modified该状态码表示客户端发送附带条件的请求时，服务端允许请求访问资源，但是未满足条件，报文中不包含任何响应的实体。 307 Temporary Redirect与302状态码有着相同的含义，但是307不会从POST变成GET。 4XX 客户端错误400 Bad Request表示报文中存在语法错误。 401 Unauthorized表示请求需要有通过HTTP认证的认证信息。 当浏览器初次接受401，会弹出认证用的对话框。 403 Forbidden表示对请求资源的访问被服务器拒绝。 比如未获得文件系统的访问授权。 404 Not Found表明服务器上无法找到请求的资源。 5XX服务器错误500 Internal Server Error该状态码表明服务器端在执行请求时发生了错误。 也有可能是 Web应用存在的 bug 或某些临时的故障。 503 Service Unavailable 表示服务器处于超负荷或者停机维护状态，无法处理请求。 参考文献《图解HTTP》上野 宣 HTTP204和205的应用 你所知道的3xx状态码]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB体系架构]]></title>
    <url>%2F2019%2F05%2F21%2FInnoDB%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[InnoDB体系架构 InnoDB是一个单进程多线程的模型。 InnoDB存储引擎分为多个内存块，可以认为这些内存块组成了一个大的内存池，负责： 维护所有进程/线程需要访问的多个内部数据结构。 缓存磁盘中的数据，方便快速的读取，同时对磁盘文件的数据修改之前在这里缓存 重做日志(redo log)缓冲 …. 后台线程的作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据。 多线程 masterThread核心后台线程，负责将缓冲池中数据异步刷新到磁盘，保证数据一致性。包括脏页刷新，合并插入缓冲等 IO ThreadInnoDB大量使用了AIO(异步IO)来处理写IO请求，极大提升数据库性能，IO Thread的主要工作就是负责这些IO请求的回调。 Pruge Thread事务被提交后，其undolog可能不再需要，因此Pruge Thread来回收已经使用并分配的undo页。 Page Cleaner ThreadPage Cleaner Thread作用是将脏页刷新放到单独的线程中操作。 脏页：所谓脏数据是指内存中的数据没有刷新到非易失存储设备上，包括但不限于更新、插入和删除等操作都会产生脏数据。 内存 缓冲池​ InnoDB存储引擎基于磁盘存储，其中的记录按照页的方式进行管理，由于CPU速度和磁盘速度差距大，基于磁盘的数据库系统通常使用缓冲池来提升整体性能。 ​ 缓冲池是一块内存区域，在数据库中进行读取页的操作，首先将磁盘中读到的页存放到缓冲池中，下一次再读取相同页时，判断是否在缓冲池中，在直接读取该页，否则从磁盘读。 ​ 对于数据库中页修改操作，首先修改缓冲池中的页，然后再以一定的频率刷新回磁盘。 LRU List Free List和Flush List​ 数据库中缓冲池通过LRU(Latest Recent Used)来管理内存的。但InnoDB对LRU算法做了一定的改进，新增了一个midpoint位置，新读取到的点放入midPoint位置。（默认为5/8处） 若直接用原始的LRU算法，那么直接读取的页将放到LRU列表首部，那么某些SQL操作会使缓冲池页被刷新出，从而影响缓冲池效率。 ​ FreeList:在数据库刚启动时，LRU列表是空的，此时现在FreeList存放页 ​ FlushList:脏页存放于Flush列表和LRU列表中，Flush列表用于管理脏页刷新回磁盘。 重做日志缓冲InnoDB引擎首先将redo log存放到缓冲区，然后按照一定的频率刷新到重做日志文件。 checkPoint技术​ checkPoint解决以下问题 缩短数据库恢复时间 缓冲池不够用时将脏页刷新回磁盘 重做日志不可用时，刷新脏页]]></content>
      <tags>
        <tag>数据库基础</tag>
        <tag>InnoDB</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表相交的一系列问题]]></title>
    <url>%2F2019%2F05%2F20%2F%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9B%B8%E4%BA%A4%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[单链表相交的一系列问题在给定的单链表中，单链表可能有环，可能无环。判断链表是否相交 ​ 要求：如果链表1的长度为N，链表2的长度为M，时间复杂度达到了O(M+N),额外空间复杂度为O(1)。 这道题需要分析的情况很多，额外空间复杂度O(1)的限制。 本题可以拆分为三个子问题，每个问题都可以作为一道独立的算法题，具体如下： 问题一：如何判断一个链表是否有环，如果有，返回第一个进入环的节点，没有则返回null。 问题二：如何判断两个无环链表是否相交，相交则返回第一个相交节点，不相交则返回null。 问题三：如何判断两个有环链表是否相交，相交返回第一个节点，不相交返回null。 问题一：判断一个链表是否有环如果链表不存在环，那么遍历链表一定可以遇到链表的终点，如果有环就会一直遍历下去，如何找到第一个入环节点 123456789101112131415161718192021222324252627282930public Node getLoopNode(Node head)&#123; if(head == null || head.next == null || head.next.next == null)&#123; return null; &#125; /*n1为慢指针，n2为快指针*/ Node n1 = head.next; Node n2 = head.next.next; /*当快慢指针没有相遇的时候*/ while(n1 != n2) &#123; /*如果快慢指针到达终点，说明链表无环*/ if(n2.next==null || n2.next.next== null) &#123; return null;&#125; n2 = n2.next.next; n1 = n1.next; &#125; /*若快慢指针相遇，说明链表有环*/ /*此时将快指针折返到头部*/ n2 = head; /*此时将快慢指针都设置为每次走一步，相遇时就是环的起点（证明略）*/ while(n1 != n2) &#123; n1 = n1.next; n2 = n2.next; &#125; return n1;&#125; 问题二：判断两个无环链表是否相交相交返回第一个节点，否则返回null。 如果两个无环链表相交，那么从相交节点到两个链表中止的这段链表是两个链表共享的。 123456789101112131415161718192021222324252627282930313233343536373839public Node noLoop(Node head1, Node head2)&#123; if(head1 == null || head2 == null) &#123;return null;&#125; /**/ Node cur1 = head1; Node cur2 = head2; int n = 0; /*遍历Node1和Node2，记录Node1和Node2的尾节点*/ while(cur1.next != null)&#123; n++; cur1 = cur1.next; &#125; while(cur2.next != null)&#123; n--; cur2 = cur2.next; &#125; /*如果链表1和链表2的尾节点不同，说明链表1和链表2不相交*/ if(cur1 != cur2)&#123; return null; &#125; /*若链表1比较长，链表1先走len1-len2步，如果是链表2，则走len2-len1步*/ /*随后两个链表一起走，第一个相交的节点就是交点*/ cur1 = n &gt; 0 ? head1 : head2; cur2 = cur1 == head1?head2:head1; n=Math.abs(n); /*长链表先走|len1-len2|步*/ while(n != 0)&#123; n--; cur1 = cur1.next; &#125; while(cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1;&#125; 问题三：如何判断两个有环链表是否相交相交返回第一个相交节点，不相交返回null。 考虑问题三的时候，我们已经得到了两个链表各自的第一个入环节点，假设链表的第一个入环节点记为loop1，链表2的第一个入环节点记为loop2。 1如果loop1 == loop2那么两个链表的拓扑结构如下 在这种情况下我们只需要考虑链表1和链表2从头开始的这一段，在哪里第一次相交即可。不过这里把loop1(loop2)作为链表的终点。 2如果loop1 != loop2两个链表不相交的拓扑结构和相交的拓扑结构如下所示。 如何分辨是哪一种拓扑结构？ 让链表1从loop1出发，因为loop1和之后 的节点都在环上，如果loop1在回到本身之前没有遇到loop2，那么链表的拓扑结构就是第一种，返回null。 否则的话，说明链表1和链表2相交，那么此时返回loop1或者loop2都可以。 具体实现如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public Node bothLoop(Node head1, Node loop1, Node head2, Node loop2)&#123; Node cur1 = null; Node cur2 = null; /*如果loop1 == loop2，这种情况下我们只需要考虑链表头节点到loop的这一段*/ /*这段代码与判断两个无环链表相交类似*/ if(loop1 == loop2)&#123; cur1 = head1; cur2 = head2; int n = 0; while(cur1 != loop1)&#123; n++; cur1 = cur1.next; &#125; while(cur2 != loop2) &#123; n--; cur2 = cur2.next; &#125; cur1 = n&gt; 0?head1:head2; cur2 = cur1 == head1?head2:head1; n = Math.abs(n); while(n!=0) &#123; cur1 = cur1.next; &#125; while(cur1 != cur2) &#123; cur1 =cur1.next; cur2 = cur2.next; &#125; return cur1; &#125;else &#123; /*如果loop1 != loop2*/ cur1 = loop.next; while(cur1 != loop1) &#123; if(cur1 == loop2)&#123; return loop1; &#125; cur1 = cur1.next; &#125; return null; &#125;&#125; 题目的主方法123456789101112131415161718192021222324public class Node&#123; public int value; public Node next; public Node(int data)&#123; this.value = data; &#125;&#125;public Node getIntersectNode(Node head1, Node head2)&#123; if(head1 == null || head2 == null)&#123; return null; &#125; Node loop1 = getLoopNode(head1); Node loop2 = getLoopNode(head2); /*如果两个链表都无环*/ if(loop1 == null &amp;&amp; loop2 == null)&#123; return noLoop(head1, head2); &#125; if(loop1 != null &amp;&amp; loop2 != null)&#123; return bothLoop(head1, loop1, head2, loop2); &#125; return null;&#125;]]></content>
      <categories>
        <category>算法题解</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS中的TLS]]></title>
    <url>%2F2019%2F05%2F20%2FHTTPS%E4%B8%AD%E7%9A%84TLS%2F</url>
    <content type="text"><![CDATA[HTTPS中的TLSSSL与TLSSSL：(Secure Socket Layer)安全套接层。 TLS：(Transport Layer Security)传输层安全协议，是IETF在SSL3.0的基础上设计的协议。 从网络协议的角度理解HTTPS HTTP：HyperText Transfer Protocol 超文本传输协议HTTPS：Hypertext Transfer Protocol Secure 超文本传输安全协议TLS：位于 HTTP 和 TCP 之间的协议，其内部有 TLS握手协议、TLS记录协议HTTPS 经由 HTTP 进行通信，但利用 TLS 来保证安全，即 HTTPS = HTTP + TLS 从密码学角度理解HTTPSHTTPS使用TLS保证安全，这里安全分为两部分，一是传输内容加密，二是服务端的身份认证。 TLS工作流程 上图为服务端单向认证，还有C/S双向认证，流程类似，但是客户端也有自己的证书，并且发送给服务器进行认证。 密码基础 伪随机数生成器 没有真正意义上的随机数，作用主要用于生产对称密码的密钥，用于公钥密码生成密钥对。 消息认证码 消息认证码：用于验证消息完整性和消息认证。（防止篡改和伪装） 发送者与接收者事先共享秘钥 发送者根据发送消息计算 MAC 值 发送者发送消息和 MAC 值 接收者根据接收到的消息计算 MAC 值 接收者根据自己计算的 MAC 值与收到的 MAC 对比 如果对比成功，说明消息完整，并来自与正确的发送者 数字签名 消息认证码缺点是无法防止否认，因为共享密钥被client, server两端拥有，server可以伪造client发送给自己的消息，这时候就需要各自的密钥不被第二个知晓。 数字签名和消息认证码都不是为了加密， 可以将单向散列函数获取的散列值的过程理解为使用md5摘要算法获取摘要的过程 使用自己的私钥对自己所认可的消息生成一个该消息专属的签名，这就是数字签名，表明我承认该消息来自自己注意：私钥用于加签，公钥用于解签，每个人都可以解签，查看消息的归属人 公钥密码公钥密码也叫非对称密码，由公钥和私钥组成，它是最开始是为了解决秘钥的配送传输安全问题，即，我们不配送私钥，只配送公钥，私钥由本人保管它与数字签名相反，公钥密码的私钥用于解密、公钥用于加密，每个人都可以用别人的公钥加密，但只有对应的私钥才能解开密文 client：明文 + 公钥 = 密文server：密文 + 私钥 = 明文注意：公钥用于加密，私钥用于解密，只有私钥的归属者，才能查看消息的真正内容 证书证书：全称公钥证书（Public-Key Certificate, PKC）,里面保存着归属者的基本信息，以及证书过期时间、归属者的公钥，并由认证机构（Certification Authority, CA）施加数字签名，表明，某个认证机构认定该公钥的确属于此人 密码小结 密码 作用 组成 消息认证码 确认消息的完整、并对消息的来源认证 共享秘钥+消息的散列值 数字签名 对消息的散列值签名 公钥+私钥+消息的散列值 公钥密码 解决秘钥的配送问题 公钥+私钥+消息 证书 解决公钥的归属问题 公钥密码中的公钥+数字签名 TLS使用的密码技术 伪随机数生成器：秘钥生成随机性，更难被猜测 对称密码：对称密码使用的秘钥就是由伪随机数生成，相较于非对称密码，效率更高 消息认证码：保证消息信息的完整性、以及验证消息信息的来源 公钥密码：证书技术使用的就是公钥密码 数字签名：验证证书的签名，确定由真实的某个 CA 颁发 证书：解决公钥的真实归属问题，降低中间人攻击概率 参考 SSL加密发生在哪里：https://security.stackexchange.com/questions/19681/where-does-ssl-encryption-take-place TLS工作流程：https://blog.csdn.net/ustccw/article/details/76691248 《图解密码技术》：https://book.douban.com/subject/26822106/ 豆瓣评分 9.5]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的使用场景]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[Redis使用场景1缓存作为key-value形态的内存数据库，使用Redis缓存数据非常简单，只需要通过String类型将序列化后的对象存起来即可。 序列化(Serialization):是将对象的状态信息转化为可以存储或传输的形式的过程。以后，可以通过从存储区中读取或反序列化对象的状态，重新创建该对象。 不过也有需要注意的地方： 必须保证不同对象的key不可以重复，并且key尽量短，一半使用类名加主键拼接而成。 选择一个有序的序列化方式也很重要，目的是提高序列化效率和减少内存占用。 缓存期间的数据一致性。一半有两种做法： 只在数据库查询后将对象放入缓存，如果对象发生了删除或者修改操作，直接清除对应缓存（或者设置为过期） 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存，或者设置为过期。 2消息队列Redis中的list的数据结构实现的是双向链表，所以可以非常便捷的应用于消息队列（生产者/消费者模型）。消息的生产者只需要通过lpush将消息放入list，消费者可以通过rpop取出该消息，并且保证消息的有序性。 如果需要实现带有优先级的消息队列也可以选择sorted list。而pub/sub也可以作为发布者/订阅者模型的消息。由于Redis带有持久化功能，无需担心由于服务器故障导致消息丢失的情况发生。 有序集合的对象编码可以是ziplist或者skiplist 3时间轴list作为双向链表，不光可以作为队列使用，如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过lpush将它存放在一个key为LATEST_WEIBO的list中。之后便可以通过lrange取出最新的微博。 4排行榜使用sortedset可以轻松打造一个热度排行榜，zrevrangebyscore可以得到以分数倒序排列的序列，zrank可以得到成员在该排行榜中的作用。 5计数器计数功能应该是最适合redis的使用场景之一，高频率读写特性完全可以发挥redis作为内存数据库的高效。在Redis的数据结构中,string, hash, 和sorted set都提供了incr方法用于原子性自增操作，下面举例说明它们各自的应用场景： 如果应用需要显示每天注册用户数，便可以使用String作为计数器，设定一个名为REGISTERED_COUNT_TODAY的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用incr命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。 每条微博都有点赞数，评论数，转发数和浏览数四条属性，这是用hash进行计数会更好，该计数器的key设为为weibo:weibo_id，hash的 field 为like_number、comment_number、forward_number和view_number，在对应操作后通过hincrby使hash 中的 field 自增。 如果应用有一个发帖排行榜的功能，便选择sorted set吧，将集合的 key 设为POST_RANK。当用户发帖后，使用zincrby将该用户 id 的 score 增长 1。sorted set会重新进行排序，用户所 在排行榜的位置也就会得到实时的更新。 6好友关系一篇介绍微博Redis应用的PPT中，其中提到微博的Redis主要用在计数和好友关系两方面， 《Redis设计与实现》中作者最开始使用Redis中的set是因为传统数据库无法计算集合的交集。 对于一个用户A，将它的关注和粉丝的用户id都存放到两个set中： A:follow:存放A所有关注的用户id A:follower:存放A所有粉丝的用户id 那么通过sinter命令便可以根据A:follow和A:follower的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，A:follow和B:follow的交集便是 A 和 B 的共同专注，A:follow和B:follower的交集便是 A 关注的人也关注了 B。 7分布式锁在Redis2.6.12版本开始，string的set命令增加了三个参数： Ex：设置键的过期时间（s） Px: 设置键的过期时间（ms) NX|XX：当设置为NX时，仅当key存在才进行操作，设置为xx时，仅当key不存在才会进行操作，这个操作是原子性的，可以简单实现一个分布式锁，例如： 1set key "lock" Ex 1 xx 如果操作返回false,说明key的添加不成功，即当前有人占用这把锁，而如果返回true,说明得到了锁，可以继续进行操作，操作后通过del释放掉锁，并且即使程序因为某些原因没有释放锁，设置了过期时间，所以该锁也会在1秒后自动释放。 8倒排索引倒排索引是构造搜索功能的最常见的方式，Redis中也可以通过set建立倒排索引，这里以简单的拼音+前缀搜索城市功能举例: 假设一个城市北京，通过拼音词库将北京转为beijing，再通过前缀分词将这两个词分为若干个前缀索引，有：北、北京、b、be…beijin和beijing。将这些索引分别作为set的 key（例如:index:北）并存储北京的 id，倒排索引便建立好了。接下来只需要在搜索时通过关键词取出对应的set并得到其中的 id 即可。 参考文献Redis应用场景 Redis在新浪微博中的应用]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据库基础</tag>
        <tag>应用场景</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之RDB持久化]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E4%B9%8BRDB%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis之RDB持久化1RDB持久化的概念​ 因为Redis数据库是一个内存数据库，一旦服务器进程退出，那么服务器中的数据库状态也会消失不见，为了解决这个问题，redis提供了RDB（Redis DataBase file）持久化功能。可以将redis中的数据库状态保存到磁盘中，避免数据的意外丢失。 2RDB文件的创建和载入​ 有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE。 SAVE会阻塞Redis服务进程，直到RDB文件完全创建完毕，在阻塞进程时服务器不能处理任何请求命令。 BGSAVE则不同，它会派生出一个子进程，由子进程负责创建RDB文件，服务器进程则继续处理请求。 3自动间隔性保存​ 因为BGSAVE命令可以在不阻塞服务器进程的情况执行。用户可以通过设置save选项设置多个保存条件，比如 123save 900 1 /*900s内有一次保存*/save 300 10 /*300sb内有10次保存*/save 60 10000 /*60s内有10000次保存*/ 只要满足上述条件之一就会触发BGSAVE命令。检查保存条件是否满足的serverCron函数默认每隔100ms就会检测一次。 4重点回顾 RDB文件用于保存和还原Redis服务器所有数据库中的所有键值对数据。 SAVE命令由服务器进程直接执行保存操作，该命令会阻塞服务器进程。 BGSAVE命令由子进程执行保存操作，不会阻塞服务器进程。 服务器状态中会保存所有用save选项设置的保存条件，当任意一个保存条件被满足时，服务器会自动执行BGSAVE命令。 RDB文件是一个经过压缩的二进制文件，由多个部分组成。 对于不同类型的键值对，RDB文件以不同的形式保存。 5RDB的缺陷​ 通过上述对RDB持久化的描述可以看出，RDB有他的不足之处，就是一旦数据库出现问题，由于RDB文件不是最新的，那么从RDB文件上一次自动保存到出现故障的这段时间内的数据就丢失了，所以RDB持久化不适用于对数据安全性要求极高的应用。]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据库基础</tag>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构之简单动态字符串]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[Redis的数据结构-简单动态字符串SDS1.SDS的定义sds结构: 123456789struct sdshdr&#123; //记录buf数组中已经使用的字节数量 //等于SDS中所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组 char[] buf&#125; SDS遵循C字符串以空字符结尾的习惯，保存空字符的一字节空间不记录到len属性中。这样的好处是可以使用部分c语言的库函数。 2.SDS与c语言字符串的区别2.1常数复杂度获取字符串长度c语言不记录自身字符串长度，需要遍历一遍得到字符串的大小。而SDS维护了len变量，直接O(1)复杂度获取。 2.2杜绝缓冲区溢出c不记录自身长度容易造成缓冲区溢出。而sds会首先检查sds的空间是否满足修改要求，不满足的话会自动实现扩容。 2.3减少修改字符串时带来的内存重新分配次数Redis作为内存数据库，经常被用于速度要求高，数据被频繁修改的场合。sds通过未使用空间解除了字符串长度和底层数组长度之间的关联。 空间预分配 当sds对sds进行修改并且sds需要扩展时，程序不仅会为sds分配修改所必须要的空间，而且还会为sds分配额外的未使用空间。 策略为，若sds长度小于1MB，则分配与len相同大小的未使用空间。即len与free属性相同。若对sds进行修改，长度大于1MB,程序会分配1MB未使用空间。 在扩容之前，会检测未使用空间是否足够，足够的话直接使用未使用空间而无需进行扩容。 惰性空间释放 当sds的api需要缩短时，并不立即内存重新分配，而是使用free属性来将这些字节数量记录并等待使用。 2.4二进制安全为了确保Redis可以使用于不同场景，SDS的API都是二进制安全的，所有的SDS API都会以处理二进制的方式来处理SDS存放在buf数组中的数据，不会对其中的数据做任何限制，过滤和假设。 2.5兼容部分c字符串函数sds遵循c字符串以空字符结尾的习惯，从而可以利用部分c的库函数]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据库基础</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构之跳跃表]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E8%B7%B3%E8%B7%83%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Redis数据结构之跳跃表1.跳跃表的定义跳跃表是一种有序数据结构，通过每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 支持平均O(logN)，最坏时间复杂度为O(N)复杂度的节点查找，还可以通过顺序性操作批量处理节点。 跳跃表在Redis里的用处：一是实现有序集合，另一个是在集群节点中用作内部数据结构。 2.跳跃表的实现Redis的跳跃表由zskiplistNode和zskiplist两个结构定义。跳跃表结构如下 左边的是zskiplist结构，该结构包含以下属性： header:指向跳跃表的表头节点。 tail：指向跳跃表的表尾节点。 level：记录目前跳跃表中节点最大的层数。（不包含表头节点） length：记录跳跃表的长度，跳跃表目前的节点数量。（不包含表头节点） 其余四个结构是zskiplistNode结构，包含以下属性： level：节点用L1，L2等字样标记节点的各个层，L1代表第一层，L2第二层以此类推，每层包含两个属性：前进指针和跨度，前进指针用于访问表尾方向的其他节点，而跨度是前进指针指向节点和当前节点的距离。 backward(后退指针)：节点中用BW字样标记节点的后退指针，指向位于当前节点的前一个节点。 score：跳跃表节点按分值由大到小排列。 obj：成员对象，指向节点保存的成员对象。 2.1跳跃表节点redis.h/zskiplistNode 123456789101112131415typedef struct zskiplistNode&#123; //层 struct zskiplistLevel&#123; //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; &#125;level[], //后退指针 struct zskiplistNode *backward; //分支 double score; //成员对象, robj *obj;&#125;zskiplistNode; 层每次创建一个新的跳跃表节点时，程序都会根据幂次定律生成一个0~32之间的数 幂次定律：越大的数生成的概率越小。 前进指针用于访问表头到表尾的节点 跨度其用途是用于计算节点在链表中的位置。 后退指针每次只能后退一个节点。 分值和成员分值用于节点间的排序。 成员对象指向一个字符串，字符串对象存放着一个SDS值。这个值代表着具体的对象类型。 2.2跳跃表实现redis.h/zskiplist 12345678typedef struct zskiplist&#123; //表头节点和表尾节点 struct zskiplistNode *header, *tail; //节点数量 int length; //表中层数最大的节点的层数 int level;&#125;zskiplist; 3总结跳跃表是有序集合的底层实现之一(另一个是压缩列表)。 跳跃表由zskiplist和zskiplistNode两个节点实现。 每个跳跃表节点的层高是1~32之间的随机数。 多个节点可以包含相同的分值，但每个节点的成员对象是唯一的。 跳跃表中节点按分值大小排序，分值相同的按对象大小排序。]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据库基础</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构之字典]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[Redis数据结构之字典字典是一种保存键值对的抽象数据结构。在字典中，一个键可以和一个值进行关联，这些关联的键和值就称为键值对。 Redis的数据库就是通过字典作为其底层实现的。对数据库的增删改查都是建立在字典的操作之上。 1.字典的实现Redis的字典使用hash表作为底层实现 1.1哈希表Redis字典所使用的哈希表结构定义如下 1234567891011121314typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used;&#125;dictht; dictEntry结构保存着一个键值对。size属性记录了哈希表大小，也即是table数组的大小。 used属性指的是当前哈希表目前已有节点的数量。 1.2哈希表节点哈希表节点用dictEntry结构表示，每个dictEntry结构都保存着一个键值对。 1234567891011121314typedef struct dictEntry&#123; //键 void *key; //值 union&#123; void *val; uint64_tu64; int64_ts64; &#125;v; //指向下个哈希表节点，形成链表 struct dictEntry *next;&#125;dicEntry; 其中键值对的值可以是一个指针，或者是uint64_t整数，又或者是一个int64_t整数。 next属性是指向另一个哈希表节点的指针，将多个哈希值相同的键值对连接在一起，以此来解决键冲突问题。 1.3字典Redis中字典由dict.h/dict结构表示: 123456789101112131415typedef struct dict&#123; //类型特定函数 dictType *type; //私有数据 void *privdata; //哈希表 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 int trehashidx;/*rehashing not in processing if rehashidx = -1;*/ &#125;dict; 其中type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个 dictType结构表存了一簇操作特定类型键值对的函数，redis 会为用途不同的字典设置不同类型的特定函数。 123456789101112typedef struct dictType&#123; //计算哈希值的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(*keyDup)(void *privdata, const void *key;) //复制值的函数 void *(*valDup)(void *privdata, const void *obj;) .... &#125; ht属性是一个包含了两个项的数组，数组中每一项都是dictht哈希表。一般情况下只使用ht[0],在rehash的时候才会使用ht[1]. 2哈希算法Redis计算哈希值和索引值的方法如下： 12#使用字典设置的哈希函数，计算键key的哈希值hash = dict-&gt;type-&gt;hashfunction（key）； 123#使用hash表的sizemask属性和哈希值计算出索引值#根据使用情况的不同，ht[x]可以是ht[0]或者ht[1]index = hash &amp; dict -&gt; ht[x].sizemask; 例如，我们要将一个键值对k0和v0添加到字典里面： 计算键k0的hash值，hash = dict-&gt;type-&gt;hashFunction(k0); 假设计算所得的hash值为8，那么程序会继续使用语句：index = hash&amp;dict-&gt;ht[0].sizemask = 8&amp;3 = 0; 计算出键k0的索引值为0，这表示包含键值对k0和v0的节点被放置到哈希表数组的索引0位置上 。 MurmurHash算法：Redis使用Murmurhash2 3解决键冲突键冲突的定义:当两个或者以上的键被分配到了hash表数组的同一个索引上，我们称这些键发生了冲突。 Redis的哈希表使用链地址法解决键冲突。其中由于dictEntry没有指向表尾的指针，新节点采取头插法。 4rehash为了让哈希表的负载因子在一个合理范围内，程序需要对哈希表进行扩展和收缩。 rehash的操作： 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量。 扩展操作，ht[1]的大小等于第一个ht[0].used*2的2^n 收缩操作，ht[1]的大小等于 第一个ht[0].used的2^n 2.将保存在ht[0]上的所有键值对rehash到ht[1]上,rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。 3.将ht[0]包含的所有键值对都迁移到ht[1]上，释放ht[0]，将ht[1]变成ht[0],并且创建一个新的ht[1]. 哈希表的负载因子计算： load_factor = ht[0].used / ht[0].size 5渐进式rehash扩展或者收缩得到哈希表需要将ht[0]里面的所有键值对rehash到ht[1]中，但是rehash的过程并不是一次性完成的，rehash的动作是分多次，渐进式地完成的。 详细步骤如下： 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个hash表。 在字典中维持一个索引计数器变量rehashidx,将其值设为0，表示rehash工作开始。 rehash进行期间，每次对字典进行增删改查时，除了执行指定操作，还顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]上。 随着字典操作的不断执行，最终在某个时间点ht[0]完全被rehash到ht[1]. 在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的增删改查需要在两个表上进行，例如，在ht[0]中未找到，继续到ht[1]里面进行查找。 参考文献《Redis设计与实现》–黄健宏，机械工业出版社]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据库基础</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP的缺点和采取措施]]></title>
    <url>%2F2019%2F05%2F19%2FHTTP%E7%9A%84%E7%BC%BA%E7%82%B9%E5%92%8C%E9%87%87%E5%8F%96%E6%8E%AA%E6%96%BD%2F</url>
    <content type="text"><![CDATA[HTTP的缺点和采取的措施1http的主要不足 通信使用明文，内容可能会被窃听。 不验证通信方身份，可能遭遇伪装。 无法证明报文完整性,可能遭到篡改。 2http加密处理措施 通信的加密：通过SSL(secure socket layer)或者TLS(Transport Layer Security安全传输协议)的组合使用。 内容的加密：通过对通信传输内容本身加密，报文主题的内容被加密处理，这需要客户端和服务端同时具有加密和解密的能力。 3http验证通信方身份措施 HTTP协议不存在验证通信方的处理步骤，任何人都可以发送请求，无法确定请求是否到达真正的服务器，无法确定响应是否返回到真的客户端，无法确定对方是否有访问权限，无法判断请求来源，无法阻止海量DOS攻击。 使用SSL可以查明对方的证书，SSL不仅提供加密服务，而且提供证书来确定对方，证书由值得信赖的第三方机构颁发，对于服务端和客户端，持有证书即可完成身份的确认。 4http验证报文完整性的措施 接收到的内容可能有误，因为http协议无法证明通信完整性，像这样在传输途中遭遇拦截并且篡改内容的攻击称为中间人攻击。常常使用SHA-1和MD5等散列值校验的方法以及确认文件的数字签名的方法。]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好，Hexo]]></title>
    <url>%2F2019%2F05%2F19%2F%E4%BD%A0%E5%A5%BD%EF%BC%8CHexo%2F</url>
    <content type="text"><![CDATA[使用Hexo，是非常简单的事情！]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>git</tag>
        <tag>前端</tag>
      </tags>
  </entry>
</search>
