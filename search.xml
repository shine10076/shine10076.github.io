<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[网路体系结构概述]]></title>
    <url>%2F2019%2F07%2F02%2F%E7%BD%91%E8%B7%AF%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[计算机网络体系结构概述主机间的通信方式客户端(C/S):客户是服务请求方，服务器是服务提供方。 对等(P2P)：不区分客户和服务器，每个既可以充当客户端，也可以充当服务器。 电路交换和分组交换1电路交换：用于电话通信系统，两个用户在通信之前需要建立专用的物理链路，并且通信过程中始终需要占据该链路。对链路利用率很低。 2分组交换：分组都有首部和尾部，包含源地址和目的地址等控制信息（五元组:源IP地址、目的IP地址、协议号、源端口、目的端口）。 时延总时延=排队时延 + 处理时延 + 传输时延 + 传播时延 五层协议应用层：为特定应用程序提供数据传输服务，例如HTTP，DNS等协议。 传输层：为进程提供通用数据传输服务。例如TCP，UDP. 网络层：为主机提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据封装为分组。 数据链路层：网络层针对的还是主机之间的服务，而主机之间有很多链路，数据链路层把网络层传下来的分组封装成帧。 物理层：物理层的作用是尽可能地屏蔽传输媒体和通信手段之间的差异。 TCP/IP四层相当于传统五层协议中的数据链路层和物理层合并为网络接口层。 网络体系概述常见面试题1.OSI与TCP/IP各层的结构和功能，都有那些协议? 结合互联网情况，自上而下 介绍各层作用。 1应用层应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程之间的通信和交互规则。不同的网络应用需要不同应用层协议，互联网中应用层协议有：DNS，HTTP，SMTP等等，应用层交互的数据单元称为报文。 域名系统： 域名系统简称DNS,是因特网上的一项核心服务，作为一个将域名和ip地址相互映射的分布式的数据库，人们能够更方便的访问互联网，不需要记住ip地址。 HTTP协议 超文本传输协议是互联网上应用最为广泛的一种网络协议，所有的万维网文件都必须遵守这个标准，设计HTTP最初的目的就是提供一种发布和接受html页面的方法。 2传输层传输层的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。通用的意思就是不针对某一个特定的网络应用，而是多种应用可以使用同一个传输层服务。一台主机可以运行多个线程，所以运输层有复用和分用的功能。 传输层协议包括： 传输控制协议TCP(Transmission Control Protocol)–提供面向连接的，可靠的数据传输服务。 用户数据协议UDP(User Datagram Protocol)–提供无连接的，尽最大努力的数据传输服务。 UDP： 无连接的 不保证可靠交付 面向报文 没有拥塞控制, 一对一，一对多，多对一的交换通信 UDP的首部开销小，8个字节，TCP20个字节 TCP： 面向连接的 每一条TCP连接只能有两个端点，每一条TCP连接都是点对点的 TCP提供可靠交付的服务，通过TCP连接传输的数据，无差错，不丢失，不重复，并且按序到达。 TCP提供全双工的通信。TCP允许通信双方在任何时候都可以发送数据，TCP连接的两端设有发送缓存和结构缓存 来临时存放双方通信的数据。 面向字节流，TCP把应用程序里的数据看作一串无结构的字节流。 3网络层在计算机网络中通信的两个计算机之间会有很多数据链路和通信子网，网络层的任务就是选择合适的网间路由和交换节点，确保数据能够及时传送。发送数据时，网络层把运输层产生的报文段和用户数据封装成分组和包进行传送。 网络层的协议主要包括ip协议和许多路由选择协议。 4数据链路层用于两台主机之间的数据传输，总是在一段段的链路上传送的专门的链路层协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装程帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。 5物理层在物理层上传送的数据单位是比特，实现了相邻计算机结点之间比特流的透明传输，尽可能屏蔽掉实际电路传送后比特流没有发生变化。]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM运行时数据区域划分]]></title>
    <url>%2F2019%2F06%2F10%2FJVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86%2F</url>
    <content type="text"><![CDATA[JVM运行时数据区域1.程序计数器程序计数器的定义：当前线程所执行的字节码的行号指示器。通过改变计数器的值选取下一条需要执行的字节码指令。分支，循环，跳转，异常处理，线程恢复等基础功能。 java虚拟机的多线程通过线程轮流切换并且分配处理器执行时间的方式来实现的。所以线程为了能在切换后恢复正确的执行位置，每个线程都需要有一个独立的程序计数器。 因此，程序计数器是线程私有的。 2.Java虚拟机栈虚拟机栈描述的是java方法执行的内存模型。每个方法在执行的同时都会创建出一个栈帧用于存储局部变量表，操作数栈，动态链接，方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧从入栈到出栈的过程。 3.本地方法栈本地方法栈与虚拟机栈的作用是十分相似的，区别在于本地方法栈为虚拟机使用的native方法服务。 4.Java堆java堆的定义：java堆是被所有线程共享的一块内存区域，虚拟机启动时创建，唯一目的就是存放对象实例，几乎所有的对象 实例都在这里创建。 Java堆是垃圾收集器管理的主要区域。 5.方法区与堆一样，方法区是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。 6.运行时常量池方法区的一部分，Class文件除了有类的模板，字段，方法，接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2019%2F06%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之单例模式单例模式(Singleton Pattern)是一个比较简单的模式，定义如下: Ensure a class has only one instance, and provide a global point of access to it. 确保一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。 以下是单例模式的几种写法： 懒汉式–线程不安全1234567891011public class Singleton&#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 代码简洁明了，使用了懒加载模式，但是在多个线程并行调用getInstance()的时候，会创建多个实例，在多线程下不能正常工作。 懒汉式–线程安全为了解决上述问题，最简单的方法就是将整个getInstance()方法设为同步(synchronized). 123456public static synchronized Singleton getInstance()&#123; if(instance == null) &#123; instance = new Singleton(); &#125; return instance;&#125; 这种方式做到了线程安全，但是并不高效，任何时候都只能有一个线程调用getInstance()方法，同步操作只有第一次调用时才需要。于是有人引出了双重检验锁。 双重检验锁双重检验锁(double checked locking pattern)是一种使用同步块加锁的方法。我们称其为双重检验锁，因为会有两次检查instance == null，一次是在同步块外，一次是在同步块内。 为什么要检查两次，因为可能会有多个线程一起进入同步块的if，如果不进行二次检验就会生成多个实例 12345678910public static Singleton getSingleton()&#123; if(instance == null)&#123; synchronized (Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance;&#125; 这段代码看上去完美，但是还是有问题，主要在于instance = new Singleton()并非是一个原子操作，事实上在JVM中这句话大概做了3件事情： 给instance分配内存 调用Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间 但是在JVM的即时编译器中存在指令重排序的优化，即上述第二步和第三步的顺序是不能保证的，最终执行顺序可能是1-2-3也可能是1-3-2。如果是后者，则在3执行完毕，2未执行之前被线程二抢占，这时instance 已经是非null(没有初始化)，线程2会直接返回instance，然后使用时报错。 我们只需要将instance变量声明为volatile 12345678910111213141516public class Singleton&#123; //声明成volatile private volatile static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized(Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; volatile关键字的作用： 保证变量在内存中的可见性 保证程序执行的顺序，volatile关键字禁止指令重排 这里其实用到的是volatile关键字的有序性，确保JVM执行时不会进行指令重排。 饿汉式–static final field直接将单例的实例声明成static和final变量，这样在类第一次加载时就在内存中初始化，所以实例本身是线程安全的。 123456789public class Singleton&#123; //类加载时就初始化 private static final Singleton instance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; 这种写法的缺点在于单例会在加载类一开始就被初始化，这导致了饿汉式在某些场景中无法使用，比如Singleton实例的创建依赖参数或者配置文件的，在getInstance()之前必须调用某个方法设置参数给它，这样这种单例写法无效了。 静态内部类 static nested class这种方法是《effective Java》上所推荐的。 12345678910public class Singleton&#123; private static class SingletonHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种写法使用JVM本身的机制来保证了线程安全的问题，由于SingletonHolder是私有的，除了getInstance()方法没有办法访问到他，同时读取实例的时候不会进行同步，没有性能缺陷，不依赖于JDK版本。 枚举 Enum用枚举写单例实在太简单了！这也是它最大的优点。下面这段代码就是声明枚举实例的通常做法。 123public enum EasySingleton&#123; INSTANCE;&#125; 我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。 几种创建方式的总结一般来说，单例模式有五种线程安全的写法：懒汉，饿汉，双重检验锁，静态内部类，枚举。 单例模式的使用场景在以下场景适合单例模式： 有频繁实例化然后销毁的情况。 创建对象耗时多或者消耗资源多而又使用频繁。 频繁访问IO资源的对象，例如数据库连接池或者访问本地文件。 比如说： 网站在线人数统计 这其实就是一个全局计数器，所有用户在同一时刻获取的在线人数数量都是一致的，这里包含分布式场景。下面代码简单实现一个计数器： 123456789101112131415161718192021public class Counter&#123; private static class CounterHolder&#123; private static final Counter counter = new Counter(); &#125; private Counter()&#123; System.out.println("init..."); &#125; private static final Counter getInstance()&#123; return CounterHolder.counter; &#125; private AtomicLong online = new AtomicLong(); public long getOnline()&#123; return online.get(); &#125; public long add()&#123; return online.increasementAndGet(); &#125;&#125; 配置文件访问类 项目种经常需要一些环境相关的配置文件，比如短信通知相关，邮件相关。比如使用Spring，可以使用@PropertySource注解实现，默认就是单例模式，不用单例的话，每次都要new对象，读取配置文件。 123456789101112131415161718192021222324252627282930313233343536public class SingleProperty&#123; private static Properties prop; private static class SinglePropertyHolder&#123; private static final SingleProperty singleProperty = new SingleProperty(); &#125; /** * config.properties 内容是 test.name=kite */ private SingleProperty()&#123; System.out.println("构造函数执行"); prop = new Properties(); InputStream stream = SingleProperty.class.getClassLoader() .getResourceAsStream("config.properties"); try &#123; prop.load(new InputStreamReader(stream, "utf-8")); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static SingleProperty getInstance()&#123; return SinglePropertyHolder.singleProperty; &#125; public String getName()&#123; return prop.get("test.name").toString(); &#125; public static void main(String[] args)&#123; SingleProperty singleProperty = SingleProperty.getInstance(); System.out.println(singleProperty.getName()); &#125;&#125; 数据库连接池的实现 做池化的原因就是新建连接十分耗时，一般做法是在应用内维护一个连接池，这样当任务进来时，如果有空闲连接可以直接拿来用，省去了初始化的开销。所以单例模式正好实现一个应用内只有一个线程池，所有的连接任务都需要从连接池里获取连接。 参考文献如何正确地写出单例模式 单例模式的使用场景]]></content>
      <categories>
        <category>面向对象基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之AOF持久化]]></title>
    <url>%2F2019%2F05%2F30%2FRedis%E4%B9%8BAOF%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis之AOF持久化Redis提供AOF(Append Only Files)持久化功能，RDB持久化通过保存数据库中键值对来记录数据库的状态，AOF持久化通过保存Redis服务器所执行的写命令来记录数据库状态。 Redis.conf配置 123appendfsync yes appendfsync always #每次有数据修改发生时都会写入AOF文件。appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。 AOF持久化的实现具体实现可以分为命令追加(append)，文件写入，文件同步三个步骤 命令追加当Redis服务器打开了AOF持久化时，服务器在执行完一个写命令后，会以协议的格式将被执行的写命令追加到服务器状态的aof_buf缓冲区末尾。 AOF文件的写入和同步使用 AOF 持久化需要设置同步选项，从而确保写命令什么时候会同步到磁盘文件上。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： 选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能，每个事件循环都要将aof_buf中的内容写入到AOF文件中，但是也是最安全的，因为即使Redis宕机也只会丢失一个事件循环的所有命令数据。 everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 AOF重写随着保存的命令越来越多，AOF文件中的内容也越来越多，而且AOF文件中的命令很有可能是冗余的，而且数据还原的时间就会越长，这时候就需要重写AOF文件来减小AOF文件的体积。 AOF文件重写的实现服务器为了保存数据库的状态，其实实际上不是去读取AOF文件来实现重写，而是直接读取数据库的状态，比如读取List的值并且用一条RPUSH list的命令行代替保存在AOF文件中。 AOF后台重写在执行BGREWRITEAOF命令时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建AOF文件期间，记录服务器所有的写命令，当子进程完成创建后，服务器会将重写缓冲区中所有的内容追加到AOF的文件末尾。最后服务器会用新的AOF文件替换旧的AOF文件 Redis4.0新功能简介：RDB-AOF混合持久化Redis用户常常会在RDB和AOF之间陷入两难： RDB持久化能够快速的恢复数据，但是在服务器停机时会丢失大量的数据； AOF持久化能够有效提高数据的安全性，但是在存储和恢复方面耗费大量的时间； Redis 4.0 推出了一个能够“鱼和熊掌兼得”的持久化方案 —— RDB-AOF 混合持久化： 这种持久化能够通过 AOF 重写操作创建出一个同时包含 RDB 数据和 AOF 数据的 AOF 文件， 其中 RDB 数据位于 AOF 文件的开头， 它们储存了服务器开始执行重写操作时的数据库状态： 至于那些在重写操作执行之后执行的 Redis 命令， 则会继续以 AOF 格式追加到 AOF 文件的末尾， 也即是 RDB 数据之后。 参考文献Redis持久化RDB和AOF优缺点是什么？ AOF和RDB持久化 Redis 4.0 新功能简介：RDB-AOF 混合持久化]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>数据库基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP中的Cookie和Session]]></title>
    <url>%2F2019%2F05%2F27%2FHTTP%E4%B8%AD%E7%9A%84Cookie%E5%92%8CSession%2F</url>
    <content type="text"><![CDATA[Cookie的机制与安全什么是Cookie？ HTTP Cookie（也叫Web Cookie或浏览器Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。 cookie，指网站为了辨别用户身份而储存在用户本地终端上的数据。cookie 本质上是 HTTP 的一个内容（请求头）。 在前端工作中，可以这么理解 cookie： cookie 是浏览器访问服务器后，服务器传给客户端的一段数据。 浏览器将 cookie 保存下来，一般情况下不会删除。 浏览器每次访问返回 cookie 的服务器时，都会在请求头（请求的第二部分）中带入这段 cookie Cookie的作用 会话状态管理（如用户登录状态，购物车，游戏分数或者其它需要） 个性化设置（用户自定义设置，主题） 浏览器行为跟踪（跟踪分析用户行为） Cookie在浏览器和服务器之间的交流过程接下来，以client指代客户端，server指代服务端，说明一个 cookie 的整个作用机制： 产生cookie:client第一次访问server，server 在响应头中设置一个 cookie 返回给 client，cookie 的内容为要保存的数据。 保存 cookie：client 在接收到 server 返回的 cookie 后，将 cookie 保存下来,并给cookie一个有效期，过了有效期，cookie 就会失效。 传递 cookie：client 再次访问 server 将会在请求头中带上保存的 cookie，将 cookie 传递到 server。 解析 cookie：server 得到 client 传递的 cookie 之后，会解析 cookie，然后将相应的信息返回给 client。在 cookie 没有失效之前，cookie 的使用都是围绕2,3,4三部分来进行的，第1步一般只需要进行一次。 Cookie存在的问题 cookie 基于浏览器本地存储数据，因此，只有在保存了 cookie 的那个浏览器上能够使用该 cookie。同一设备不同浏览器之间，cookie 不通用。 cookie 的存储大小有限制： 4KB 左右。 cookie 存在C盘的一个文件中，不同浏览器存储路劲不一样。 cookie 是可以被用户手动修改的。 cookie 的有效期：默认有效期20分钟左右。可以通过后端强制设置有效期，如自动登录时间。 cookie 的同源策略：cookie 同样也有同源策略，不过与 ajax 略微不用。ajax 需要完全同源，而 cookie 只需要同一父级域名即可。 比如： 请求 qq.com 下的资源时，会带上 qq.com 对应的 cookie，不会带上 baidu.com 的 cookie； 请求 v.qq.com 下的资源时，浏览器不仅会带上 v.qq.com 的 cookie，还会带上 qq.com 的cookie。在这里，qq.com 就是 v.qq.com 的父级域名。 需要特别注意的一点是：在浏览器的认知中，www.qq.com和qq.com是两个不同的域名。因此，www.qq.com 不是 v.qq.com 的父域名，qq.com才是。 由于 cookie 是明文保存在客户端的数据，可能会被客户端修改，存在信息泄露的风险，所以，需要一种比 cookie 更加安全的存储方式来存储数据。session 就是解决安全问题的方法。 Cookie: HttpOnly标记为HttpOnly的Cookie不能被JavaScript脚本调用，跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 Cookie的安全隐患Cookie提供了一种手段使得HTTP请求附加当前的状态，网站也是靠Cookie标识用户登录状态的： 用户提交用户名和密码的表单，通常是一个POST HTTP请求。 服务器验证用户名与密码，如果合法则返回200（OK）并设置Set-Cookie为authed=true。 浏览器存储该Cookie。 浏览器发送请求时，设置Cookie字段为authed=true。 服务器收到第二次请求，从Cookie字段得知该用户已经登录。 按照已登录用户的权限来处理此次请求。 但是不仅浏览器可以发送HTTP请求，许多HTTP客户端软件也可以发送，可以设置任何头字段，假如我们直接设置Cookie字段为authed=true并发送该HTTP请求， 服务器岂不是被欺骗了？这种攻击非常容易，Cookie是可以被篡改的！ Cookie的防篡改机制服务器可以为每个Cookie项生成签名，由于用户篡改Cookie后无法生成对应的签名， 服务器便可以得知用户对Cookie进行了篡改。一个简单的校验过程可能是这样的： 在服务器中配置一个不为人知的字符串（我们叫它Secret），比如：x$sfz32。 当服务器需要设置Cookie时（比如authed=false），不仅设置authed的值为false， 在值的后面进一步设置一个签名，最终设置的Cookie是authed=false|6hTiBl7lVpd1P。 签名6hTiBl7lVpd1P是这样生成的：Hash(&#39;x$sfz32&#39;+&#39;false&#39;)。 要设置的值与Secret相加再取哈希。 用户收到HTTP响应并发现头字段Set-Cookie: authed=false|6hTiBl7lVpd1P。 用户在发送HTTP请求时，篡改了authed值，设置头字段Cookie: authed=true|???。 因为用户不知道Secret，无法生成签名，只能随便填一个。 服务器收到HTTP请求，发现Cookie: authed=true|???。服务器开始进行校验： Hash(&#39;true&#39;+&#39;x$sfz32&#39;)，便会发现用户提供的签名不正确。 通过给Cookie添加签名，使得服务器得以知道Cookie被篡改。 因为Cookie是明文传输的， 只要服务器设置过一次authed=true|xxxx我不就知道true的签名是xxxx了么， 以后就可以用这个签名来欺骗服务器了。因此Cookie中最好不要放敏感数据。 一般来讲Cookie中只会放一个Session Id，而Session存储在服务器端。 Session的机制和安全Session的定义 在计算机科学领域来说，尤其是在网络领域，会话（session）是一种持久网络协议，在用户（或用户代理）端和服务器端之间创建关联，从而起到交换数据包的作用机制，session在网络协议（例如telnet或FTP）中是非常重要的部分。 个人理解： session 是一种在服务器端保存数据的机制。服务器通过读取浏览器发送的 cookie 和 服务器端的 session 来交换数据。 不同于 cookie，session保存在服务器端，不同的语言保存方式不一样： java，保存于服务器内存中，重启服务器，session 消失 php，保存于服务器文件中，重启服务器，session 依然存在 nodejs，保存于服务器内存中，重启服务器，sessino 消失 Session的作用和Cookie大致相同，但是最大的不同点在于两者实现的安全性和实现方式。 Session的实现依然将客户端称为 client，服务端成为 server。 1.产生 sessionID：session 是基于 cookie 的一种方案，所以，首先要产生 cookie。client 第一次访问 server，server 生成一个随机数，命名为 sessionID，并将其放在响应头里，以 cookie 的形式返回给 client，client 以处理其他 cookie 的方式处理这段 cookie。大概是这样：cookie：sessionID=135165432165 2.保存 sessionID： server 将要保存的数据保存在相对应的 sessionID 之下，再将 sessionID 保存到服务器端的特定的保存 session 的内存中（如 一个叫 session 的哈希表） 3.使用 session： client 再次访问 server，会带上首次访问时获得的 值为 sessionID 的cookie，server 读取 cookie 中的 sessionID，根据 sessionID 到保存 session 的内存寻找与 sessionID 匹配的数据，若寻找成功就将数据返回给 client。 Session 与 cookie 的区别 session 在服务器端，cookie 在客户端。 session 用户无法查看和修改，cookie 用户可以查看修改。 session 和 cookie 的存储容量不同。 session 的实现依赖于 sessionID，而 sessionID 又存储在 cookie 上，所以，可以这么说：session 是基于 cookie 实现的一种数据存储方式。 Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 参考文献《图解HTTP》 日 上野宣 详解cookie、session和HTTP缓存 HTTP cookies 详解 COOKIE和SESSION有什么区别？]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP中的方法]]></title>
    <url>%2F2019%2F05%2F26%2FHTTP%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[HTTP中的方法GET:获取资源GET方法用来请求访问已被URI识别的资源。指定资源经服务器端解析后返回响应内容。 POST：传输实体主体POST方法用来传输实体的主体 虽然用GET方法也可以传输实体的主体，但是一般不用GET方法。 PUT：传输文件用来传输文件，就像FTP协议的文件上传。 HEAD：获取报文首部HEAD 方法和 GET 方法一样， 只是不返回报文主体部分。 用于确认URI 的有效性及资源更新的日期时间等 DELETE: 删除文件DELETE 方法用来删除文件， 是与 PUT 相反的方法。 DELETE 方法按请求 URI 删除指定的资源 。 OPTIONS：询问支持的方法OPTIONS方法用来查询针对请求URI指定的资源支持的方法 TRACES：追踪路径TRACE方法是让web服务器端将之前的请求通信环回给客户端的方法。 Connect：要求用隧道协议代理链接CONNECT 方法要求在与代理服务器通信时建立隧道， 实现用隧道协议进行 TCP 通信。 主要使用 SSL（Secure Sockets Layer， 安全套接层） 和 TLS（Transport Layer Security， 传输层安全） 协议把通信内容加 密后经网络隧道传输。 HTTP/1.0和HTTP/1.1支持的方法 方法 说明 支持的 HTTP 协议版本 GET 获取资源 1.0、 1.1 POST 传输实体主体 1.0、 1.1 PUT 传输文件 1.0、 1.1 HEAD 获得报文首部 1.0、 1.1 DELETE 删除文件 1.0、 1.1 OPTIONS 询问支持的方法 1.1 TRACE 追踪路径 1.1 CONNECT 要求用隧道协议连接代理 1.1 LINK 建立和资源之间的联系 1.0 UNLINE 断开连接关系 1.0 GET和POST对比作用GET用于获取资源，而POST用于传输实体主体。 参数GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。 因为GET是通过URL提交数据的，所以GET可提交的数据量就和URL的长度有关。HTTP没有限制URL长度，但浏览器会限制URL长度 而POST方法则是把提交的数据放置在HTTP包的包体中。 连接对于GET方式请求，浏览器会把http header和data一并发送出去，服务器响应200。 对于POST方式请求，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 OK。但是不是所有的浏览器都会发送两次包，比如火狐。 安全安全的HTTP方法不会改变服务器状态，它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 幂等性GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的： 1234GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1Copy to clipboardErrorCopied POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录： 123POST /add_row HTTP/1.1 -&gt; Adds a 1nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 2nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 3rd rowCopy to clipboardErrorCopied DELETE /idX/delete HTTP/1.1 是幂等的，即使不同的请求接收到的状态码不一样： 123DELETE /idX/delete HTTP/1.1 -&gt; Returns 200 if idX existsDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 as it just got deletedDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 可缓存如果要对响应进行缓存，需要满足以下条件： 请求报文的HTTP方法是可以缓存的，包括GET和HEAD，但是PUT和DELELTE不可缓存，POST在多数情况下不可缓存。 响应报文的状态码时刻缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的Cache-Control首部字段没有指定不可缓存。 XMLHttpRequest为了阐述POST和GET的另一个区别，需要先了解XMLHttpRequest: XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。 参考文献《图解HTTP》日，上野宣. 9%的人理解错 HTTP 中 GET 与 POST 的区别 HTTP中Get与Post的区别]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP状态码详解]]></title>
    <url>%2F2019%2F05%2F23%2FHTTP%E7%8A%B6%E6%80%81%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[HTTP状态码HTTP状态码类别 类别 原因短语 1XX Informational（信息性状态码) 接受的请求正在处理 2XX Success(成功性状态码) 请求正常处理完毕 3XX Redirection(重定向状态码) 需要进行附加操作以完成请求 4XX Client Error(客户端错误状态码) 服务器无法处理请求 5XX Server Error(服务器错误状态码) 服务器处理请求出错 2XX成功2xx的响应结果表示请求被正常处理。 200OK表示客户端发来的请求被服务端正常处理。 例如GET方法对应请求资源的实体作为响应返回，HEAD方法对应请求资源的实体首部不随报文主体作为响应返回。 204 No Content表示服务器接受的请求已经成功处理，但是在返回的响应报文中不包含实体的主体部分。也不允许返回任何实体主体。 1&#123;status: 0, message:""&#125; //status 0代表成功, 非零的时候, message中包含出错信息. 所以有一些服务, 只是返回成功与否的时候, 可以尝试使用HTTP的状态码来作为返回信息, 而省掉多余的数据传输, 比如REST中的DELETE和上述Ajax请求. 206 Partial Content该状态码表示客户端进行了范围请求，而服务器成功执行了这部分GET请求。响应报文中包含Content-Range指定范围的实体内容。 3XX重定向3XX表示浏览器需要执行某些特殊处理以正确处理请求。 301 Moved Permanently表示请求资源被分配了新的URI，这种对搜索引擎是友好的，一旦网页a永久定位到网页b，那么使用301重定向后，搜索引擎会将a的累积权重传到网页b。(例如Google会传大部分权重) 302 Found临时性重定向，表示该资源已被重新分配了URI，希望这次能够用新的URI访问。 303 See Other表示请求对应的资源存在另一个URI，应该使用GET方法定向获取请求资源。 303主要目的是允许POST请求的响应将客户端定位到某个资源上。比如说，在文件上传完成后让客户端自动重定向到一个上传成功的结果页面。 304 Not Modified该状态码表示客户端发送附带条件的请求时，服务端允许请求访问资源，但是未满足条件，报文中不包含任何响应的实体。 307 Temporary Redirect与302状态码有着相同的含义，但是307不会从POST变成GET。 4XX 客户端错误400 Bad Request表示报文中存在语法错误。 401 Unauthorized表示请求需要有通过HTTP认证的认证信息。 当浏览器初次接受401，会弹出认证用的对话框。 403 Forbidden表示对请求资源的访问被服务器拒绝。 比如未获得文件系统的访问授权。 404 Not Found表明服务器上无法找到请求的资源。 5XX服务器错误500 Internal Server Error该状态码表明服务器端在执行请求时发生了错误。 也有可能是 Web应用存在的 bug 或某些临时的故障。 503 Service Unavailable 表示服务器处于超负荷或者停机维护状态，无法处理请求。 参考文献《图解HTTP》上野 宣 HTTP204和205的应用 你所知道的3xx状态码]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB体系架构]]></title>
    <url>%2F2019%2F05%2F21%2FInnoDB%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[InnoDB体系架构 InnoDB是一个单进程多线程的模型。 InnoDB存储引擎分为多个内存块，可以认为这些内存块组成了一个大的内存池，负责： 维护所有进程/线程需要访问的多个内部数据结构。 缓存磁盘中的数据，方便快速的读取，同时对磁盘文件的数据修改之前在这里缓存 重做日志(redo log)缓冲 …. 后台线程的作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据。 多线程 masterThread核心后台线程，负责将缓冲池中数据异步刷新到磁盘，保证数据一致性。包括脏页刷新，合并插入缓冲等 IO ThreadInnoDB大量使用了AIO(异步IO)来处理写IO请求，极大提升数据库性能，IO Thread的主要工作就是负责这些IO请求的回调。 Pruge Thread事务被提交后，其undolog可能不再需要，因此Pruge Thread来回收已经使用并分配的undo页。 Page Cleaner ThreadPage Cleaner Thread作用是将脏页刷新放到单独的线程中操作。 脏页：所谓脏数据是指内存中的数据没有刷新到非易失存储设备上，包括但不限于更新、插入和删除等操作都会产生脏数据。 内存 缓冲池​ InnoDB存储引擎基于磁盘存储，其中的记录按照页的方式进行管理，由于CPU速度和磁盘速度差距大，基于磁盘的数据库系统通常使用缓冲池来提升整体性能。 ​ 缓冲池是一块内存区域，在数据库中进行读取页的操作，首先将磁盘中读到的页存放到缓冲池中，下一次再读取相同页时，判断是否在缓冲池中，在直接读取该页，否则从磁盘读。 ​ 对于数据库中页修改操作，首先修改缓冲池中的页，然后再以一定的频率刷新回磁盘。 LRU List Free List和Flush List​ 数据库中缓冲池通过LRU(Latest Recent Used)来管理内存的。但InnoDB对LRU算法做了一定的改进，新增了一个midpoint位置，新读取到的点放入midPoint位置。（默认为5/8处） 若直接用原始的LRU算法，那么直接读取的页将放到LRU列表首部，那么某些SQL操作会使缓冲池页被刷新出，从而影响缓冲池效率。 ​ FreeList:在数据库刚启动时，LRU列表是空的，此时现在FreeList存放页 ​ FlushList:脏页存放于Flush列表和LRU列表中，Flush列表用于管理脏页刷新回磁盘。 重做日志缓冲InnoDB引擎首先将redo log存放到缓冲区，然后按照一定的频率刷新到重做日志文件。 checkPoint技术​ checkPoint解决以下问题 缩短数据库恢复时间 缓冲池不够用时将脏页刷新回磁盘 重做日志不可用时，刷新脏页]]></content>
      <tags>
        <tag>数据库基础</tag>
        <tag>InnoDB</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表相交的一系列问题]]></title>
    <url>%2F2019%2F05%2F20%2F%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9B%B8%E4%BA%A4%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[单链表相交的一系列问题在给定的单链表中，单链表可能有环，可能无环。判断链表是否相交 ​ 要求：如果链表1的长度为N，链表2的长度为M，时间复杂度达到了O(M+N),额外空间复杂度为O(1)。 这道题需要分析的情况很多，额外空间复杂度O(1)的限制。 本题可以拆分为三个子问题，每个问题都可以作为一道独立的算法题，具体如下： 问题一：如何判断一个链表是否有环，如果有，返回第一个进入环的节点，没有则返回null。 问题二：如何判断两个无环链表是否相交，相交则返回第一个相交节点，不相交则返回null。 问题三：如何判断两个有环链表是否相交，相交返回第一个节点，不相交返回null。 问题一：判断一个链表是否有环如果链表不存在环，那么遍历链表一定可以遇到链表的终点，如果有环就会一直遍历下去，如何找到第一个入环节点 123456789101112131415161718192021222324252627282930public Node getLoopNode(Node head)&#123; if(head == null || head.next == null || head.next.next == null)&#123; return null; &#125; /*n1为慢指针，n2为快指针*/ Node n1 = head.next; Node n2 = head.next.next; /*当快慢指针没有相遇的时候*/ while(n1 != n2) &#123; /*如果快慢指针到达终点，说明链表无环*/ if(n2.next==null || n2.next.next== null) &#123; return null;&#125; n2 = n2.next.next; n1 = n1.next; &#125; /*若快慢指针相遇，说明链表有环*/ /*此时将快指针折返到头部*/ n2 = head; /*此时将快慢指针都设置为每次走一步，相遇时就是环的起点（证明略）*/ while(n1 != n2) &#123; n1 = n1.next; n2 = n2.next; &#125; return n1;&#125; 问题二：判断两个无环链表是否相交相交返回第一个节点，否则返回null。 如果两个无环链表相交，那么从相交节点到两个链表中止的这段链表是两个链表共享的。 123456789101112131415161718192021222324252627282930313233343536373839public Node noLoop(Node head1, Node head2)&#123; if(head1 == null || head2 == null) &#123;return null;&#125; /**/ Node cur1 = head1; Node cur2 = head2; int n = 0; /*遍历Node1和Node2，记录Node1和Node2的尾节点*/ while(cur1.next != null)&#123; n++; cur1 = cur1.next; &#125; while(cur2.next != null)&#123; n--; cur2 = cur2.next; &#125; /*如果链表1和链表2的尾节点不同，说明链表1和链表2不相交*/ if(cur1 != cur2)&#123; return null; &#125; /*若链表1比较长，链表1先走len1-len2步，如果是链表2，则走len2-len1步*/ /*随后两个链表一起走，第一个相交的节点就是交点*/ cur1 = n &gt; 0 ? head1 : head2; cur2 = cur1 == head1?head2:head1; n=Math.abs(n); /*长链表先走|len1-len2|步*/ while(n != 0)&#123; n--; cur1 = cur1.next; &#125; while(cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1;&#125; 问题三：如何判断两个有环链表是否相交相交返回第一个相交节点，不相交返回null。 考虑问题三的时候，我们已经得到了两个链表各自的第一个入环节点，假设链表的第一个入环节点记为loop1，链表2的第一个入环节点记为loop2。 1如果loop1 == loop2那么两个链表的拓扑结构如下 在这种情况下我们只需要考虑链表1和链表2从头开始的这一段，在哪里第一次相交即可。不过这里把loop1(loop2)作为链表的终点。 2如果loop1 != loop2两个链表不相交的拓扑结构和相交的拓扑结构如下所示。 如何分辨是哪一种拓扑结构？ 让链表1从loop1出发，因为loop1和之后 的节点都在环上，如果loop1在回到本身之前没有遇到loop2，那么链表的拓扑结构就是第一种，返回null。 否则的话，说明链表1和链表2相交，那么此时返回loop1或者loop2都可以。 具体实现如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public Node bothLoop(Node head1, Node loop1, Node head2, Node loop2)&#123; Node cur1 = null; Node cur2 = null; /*如果loop1 == loop2，这种情况下我们只需要考虑链表头节点到loop的这一段*/ /*这段代码与判断两个无环链表相交类似*/ if(loop1 == loop2)&#123; cur1 = head1; cur2 = head2; int n = 0; while(cur1 != loop1)&#123; n++; cur1 = cur1.next; &#125; while(cur2 != loop2) &#123; n--; cur2 = cur2.next; &#125; cur1 = n&gt; 0?head1:head2; cur2 = cur1 == head1?head2:head1; n = Math.abs(n); while(n!=0) &#123; cur1 = cur1.next; &#125; while(cur1 != cur2) &#123; cur1 =cur1.next; cur2 = cur2.next; &#125; return cur1; &#125;else &#123; /*如果loop1 != loop2*/ cur1 = loop.next; while(cur1 != loop1) &#123; if(cur1 == loop2)&#123; return loop1; &#125; cur1 = cur1.next; &#125; return null; &#125;&#125; 题目的主方法123456789101112131415161718192021222324public class Node&#123; public int value; public Node next; public Node(int data)&#123; this.value = data; &#125;&#125;public Node getIntersectNode(Node head1, Node head2)&#123; if(head1 == null || head2 == null)&#123; return null; &#125; Node loop1 = getLoopNode(head1); Node loop2 = getLoopNode(head2); /*如果两个链表都无环*/ if(loop1 == null &amp;&amp; loop2 == null)&#123; return noLoop(head1, head2); &#125; if(loop1 != null &amp;&amp; loop2 != null)&#123; return bothLoop(head1, loop1, head2, loop2); &#125; return null;&#125;]]></content>
      <categories>
        <category>算法题解</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS中的TLS]]></title>
    <url>%2F2019%2F05%2F20%2FHTTPS%E4%B8%AD%E7%9A%84TLS%2F</url>
    <content type="text"><![CDATA[HTTPS中的TLSSSL与TLSSSL：(Secure Socket Layer)安全套接层。 TLS：(Transport Layer Security)传输层安全协议，是IETF在SSL3.0的基础上设计的协议。 从网络协议的角度理解HTTPS HTTP：HyperText Transfer Protocol 超文本传输协议HTTPS：Hypertext Transfer Protocol Secure 超文本传输安全协议TLS：位于 HTTP 和 TCP 之间的协议，其内部有 TLS握手协议、TLS记录协议HTTPS 经由 HTTP 进行通信，但利用 TLS 来保证安全，即 HTTPS = HTTP + TLS 从密码学角度理解HTTPSHTTPS使用TLS保证安全，这里安全分为两部分，一是传输内容加密，二是服务端的身份认证。 TLS工作流程 上图为服务端单向认证，还有C/S双向认证，流程类似，但是客户端也有自己的证书，并且发送给服务器进行认证。 密码基础 伪随机数生成器 没有真正意义上的随机数，作用主要用于生产对称密码的密钥，用于公钥密码生成密钥对。 消息认证码 消息认证码：用于验证消息完整性和消息认证。（防止篡改和伪装） 发送者与接收者事先共享秘钥 发送者根据发送消息计算 MAC 值 发送者发送消息和 MAC 值 接收者根据接收到的消息计算 MAC 值 接收者根据自己计算的 MAC 值与收到的 MAC 对比 如果对比成功，说明消息完整，并来自与正确的发送者 数字签名 消息认证码缺点是无法防止否认，因为共享密钥被client, server两端拥有，server可以伪造client发送给自己的消息，这时候就需要各自的密钥不被第二个知晓。 数字签名和消息认证码都不是为了加密， 可以将单向散列函数获取的散列值的过程理解为使用md5摘要算法获取摘要的过程 使用自己的私钥对自己所认可的消息生成一个该消息专属的签名，这就是数字签名，表明我承认该消息来自自己注意：私钥用于加签，公钥用于解签，每个人都可以解签，查看消息的归属人 公钥密码公钥密码也叫非对称密码，由公钥和私钥组成，它是最开始是为了解决秘钥的配送传输安全问题，即，我们不配送私钥，只配送公钥，私钥由本人保管它与数字签名相反，公钥密码的私钥用于解密、公钥用于加密，每个人都可以用别人的公钥加密，但只有对应的私钥才能解开密文 client：明文 + 公钥 = 密文server：密文 + 私钥 = 明文注意：公钥用于加密，私钥用于解密，只有私钥的归属者，才能查看消息的真正内容 证书证书：全称公钥证书（Public-Key Certificate, PKC）,里面保存着归属者的基本信息，以及证书过期时间、归属者的公钥，并由认证机构（Certification Authority, CA）施加数字签名，表明，某个认证机构认定该公钥的确属于此人 密码小结 密码 作用 组成 消息认证码 确认消息的完整、并对消息的来源认证 共享秘钥+消息的散列值 数字签名 对消息的散列值签名 公钥+私钥+消息的散列值 公钥密码 解决秘钥的配送问题 公钥+私钥+消息 证书 解决公钥的归属问题 公钥密码中的公钥+数字签名 TLS使用的密码技术 伪随机数生成器：秘钥生成随机性，更难被猜测 对称密码：对称密码使用的秘钥就是由伪随机数生成，相较于非对称密码，效率更高 消息认证码：保证消息信息的完整性、以及验证消息信息的来源 公钥密码：证书技术使用的就是公钥密码 数字签名：验证证书的签名，确定由真实的某个 CA 颁发 证书：解决公钥的真实归属问题，降低中间人攻击概率 参考 SSL加密发生在哪里：https://security.stackexchange.com/questions/19681/where-does-ssl-encryption-take-place TLS工作流程：https://blog.csdn.net/ustccw/article/details/76691248 《图解密码技术》：https://book.douban.com/subject/26822106/ 豆瓣评分 9.5]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的使用场景]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[Redis使用场景1缓存作为key-value形态的内存数据库，使用Redis缓存数据非常简单，只需要通过String类型将序列化后的对象存起来即可。 序列化(Serialization):是将对象的状态信息转化为可以存储或传输的形式的过程。以后，可以通过从存储区中读取或反序列化对象的状态，重新创建该对象。 不过也有需要注意的地方： 必须保证不同对象的key不可以重复，并且key尽量短，一半使用类名加主键拼接而成。 选择一个有序的序列化方式也很重要，目的是提高序列化效率和减少内存占用。 缓存期间的数据一致性。一半有两种做法： 只在数据库查询后将对象放入缓存，如果对象发生了删除或者修改操作，直接清除对应缓存（或者设置为过期） 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存，或者设置为过期。 2消息队列Redis中的list的数据结构实现的是双向链表，所以可以非常便捷的应用于消息队列（生产者/消费者模型）。消息的生产者只需要通过lpush将消息放入list，消费者可以通过rpop取出该消息，并且保证消息的有序性。 如果需要实现带有优先级的消息队列也可以选择sorted list。而pub/sub也可以作为发布者/订阅者模型的消息。由于Redis带有持久化功能，无需担心由于服务器故障导致消息丢失的情况发生。 有序集合的对象编码可以是ziplist或者skiplist 3时间轴list作为双向链表，不光可以作为队列使用，如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过lpush将它存放在一个key为LATEST_WEIBO的list中。之后便可以通过lrange取出最新的微博。 4排行榜使用sortedset可以轻松打造一个热度排行榜，zrevrangebyscore可以得到以分数倒序排列的序列，zrank可以得到成员在该排行榜中的作用。 5计数器计数功能应该是最适合redis的使用场景之一，高频率读写特性完全可以发挥redis作为内存数据库的高效。在Redis的数据结构中,string, hash, 和sorted set都提供了incr方法用于原子性自增操作，下面举例说明它们各自的应用场景： 如果应用需要显示每天注册用户数，便可以使用String作为计数器，设定一个名为REGISTERED_COUNT_TODAY的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用incr命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。 每条微博都有点赞数，评论数，转发数和浏览数四条属性，这是用hash进行计数会更好，该计数器的key设为为weibo:weibo_id，hash的 field 为like_number、comment_number、forward_number和view_number，在对应操作后通过hincrby使hash 中的 field 自增。 如果应用有一个发帖排行榜的功能，便选择sorted set吧，将集合的 key 设为POST_RANK。当用户发帖后，使用zincrby将该用户 id 的 score 增长 1。sorted set会重新进行排序，用户所 在排行榜的位置也就会得到实时的更新。 6好友关系一篇介绍微博Redis应用的PPT中，其中提到微博的Redis主要用在计数和好友关系两方面， 《Redis设计与实现》中作者最开始使用Redis中的set是因为传统数据库无法计算集合的交集。 对于一个用户A，将它的关注和粉丝的用户id都存放到两个set中： A:follow:存放A所有关注的用户id A:follower:存放A所有粉丝的用户id 那么通过sinter命令便可以根据A:follow和A:follower的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，A:follow和B:follow的交集便是 A 和 B 的共同专注，A:follow和B:follower的交集便是 A 关注的人也关注了 B。 7分布式锁在Redis2.6.12版本开始，string的set命令增加了三个参数： Ex：设置键的过期时间（s） Px: 设置键的过期时间（ms) NX|XX：当设置为NX时，仅当key存在才进行操作，设置为xx时，仅当key不存在才会进行操作，这个操作是原子性的，可以简单实现一个分布式锁，例如： 1set key "lock" Ex 1 xx 如果操作返回false,说明key的添加不成功，即当前有人占用这把锁，而如果返回true,说明得到了锁，可以继续进行操作，操作后通过del释放掉锁，并且即使程序因为某些原因没有释放锁，设置了过期时间，所以该锁也会在1秒后自动释放。 8倒排索引倒排索引是构造搜索功能的最常见的方式，Redis中也可以通过set建立倒排索引，这里以简单的拼音+前缀搜索城市功能举例: 假设一个城市北京，通过拼音词库将北京转为beijing，再通过前缀分词将这两个词分为若干个前缀索引，有：北、北京、b、be…beijin和beijing。将这些索引分别作为set的 key（例如:index:北）并存储北京的 id，倒排索引便建立好了。接下来只需要在搜索时通过关键词取出对应的set并得到其中的 id 即可。 参考文献Redis应用场景 Redis在新浪微博中的应用]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Redis</tag>
        <tag>应用场景</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之RDB持久化]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E4%B9%8BRDB%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis之RDB持久化1RDB持久化的概念​ 因为Redis数据库是一个内存数据库，一旦服务器进程退出，那么服务器中的数据库状态也会消失不见，为了解决这个问题，redis提供了RDB（Redis DataBase file）持久化功能。可以将redis中的数据库状态保存到磁盘中，避免数据的意外丢失。 2RDB文件的创建和载入​ 有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE。 SAVE会阻塞Redis服务进程，直到RDB文件完全创建完毕，在阻塞进程时服务器不能处理任何请求命令。 BGSAVE则不同，它会派生出一个子进程，由子进程负责创建RDB文件，服务器进程则继续处理请求。 3自动间隔性保存​ 因为BGSAVE命令可以在不阻塞服务器进程的情况执行。用户可以通过设置save选项设置多个保存条件，比如 123save 900 1 /*900s内有一次保存*/save 300 10 /*300sb内有10次保存*/save 60 10000 /*60s内有10000次保存*/ 只要满足上述条件之一就会触发BGSAVE命令。检查保存条件是否满足的serverCron函数默认每隔100ms就会检测一次。 4重点回顾 RDB文件用于保存和还原Redis服务器所有数据库中的所有键值对数据。 SAVE命令由服务器进程直接执行保存操作，该命令会阻塞服务器进程。 BGSAVE命令由子进程执行保存操作，不会阻塞服务器进程。 服务器状态中会保存所有用save选项设置的保存条件，当任意一个保存条件被满足时，服务器会自动执行BGSAVE命令。 RDB文件是一个经过压缩的二进制文件，由多个部分组成。 对于不同类型的键值对，RDB文件以不同的形式保存。 5RDB的缺陷​ 通过上述对RDB持久化的描述可以看出，RDB有他的不足之处，就是一旦数据库出现问题，由于RDB文件不是最新的，那么从RDB文件上一次自动保存到出现故障的这段时间内的数据就丢失了，所以RDB持久化不适用于对数据安全性要求极高的应用。]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Redis</tag>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构之简单动态字符串]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[Redis的数据结构-简单动态字符串SDS1.SDS的定义sds结构: 123456789struct sdshdr&#123; //记录buf数组中已经使用的字节数量 //等于SDS中所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组 char[] buf&#125; SDS遵循C字符串以空字符结尾的习惯，保存空字符的一字节空间不记录到len属性中。这样的好处是可以使用部分c语言的库函数。 2.SDS与c语言字符串的区别2.1常数复杂度获取字符串长度c语言不记录自身字符串长度，需要遍历一遍得到字符串的大小。而SDS维护了len变量，直接O(1)复杂度获取。 2.2杜绝缓冲区溢出c不记录自身长度容易造成缓冲区溢出。而sds会首先检查sds的空间是否满足修改要求，不满足的话会自动实现扩容。 2.3减少修改字符串时带来的内存重新分配次数Redis作为内存数据库，经常被用于速度要求高，数据被频繁修改的场合。sds通过未使用空间解除了字符串长度和底层数组长度之间的关联。 空间预分配 当sds对sds进行修改并且sds需要扩展时，程序不仅会为sds分配修改所必须要的空间，而且还会为sds分配额外的未使用空间。 策略为，若sds长度小于1MB，则分配与len相同大小的未使用空间。即len与free属性相同。若对sds进行修改，长度大于1MB,程序会分配1MB未使用空间。 在扩容之前，会检测未使用空间是否足够，足够的话直接使用未使用空间而无需进行扩容。 惰性空间释放 当sds的api需要缩短时，并不立即内存重新分配，而是使用free属性来将这些字节数量记录并等待使用。 2.4二进制安全为了确保Redis可以使用于不同场景，SDS的API都是二进制安全的，所有的SDS API都会以处理二进制的方式来处理SDS存放在buf数组中的数据，不会对其中的数据做任何限制，过滤和假设。 2.5兼容部分c字符串函数sds遵循c字符串以空字符结尾的习惯，从而可以利用部分c的库函数]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Redis</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构之跳跃表]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E8%B7%B3%E8%B7%83%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Redis数据结构之跳跃表1.跳跃表的定义跳跃表是一种有序数据结构，通过每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 支持平均O(logN)，最坏时间复杂度为O(N)复杂度的节点查找，还可以通过顺序性操作批量处理节点。 跳跃表在Redis里的用处：一是实现有序集合，另一个是在集群节点中用作内部数据结构。 2.跳跃表的实现Redis的跳跃表由zskiplistNode和zskiplist两个结构定义。跳跃表结构如下 左边的是zskiplist结构，该结构包含以下属性： header:指向跳跃表的表头节点。 tail：指向跳跃表的表尾节点。 level：记录目前跳跃表中节点最大的层数。（不包含表头节点） length：记录跳跃表的长度，跳跃表目前的节点数量。（不包含表头节点） 其余四个结构是zskiplistNode结构，包含以下属性： level：节点用L1，L2等字样标记节点的各个层，L1代表第一层，L2第二层以此类推，每层包含两个属性：前进指针和跨度，前进指针用于访问表尾方向的其他节点，而跨度是前进指针指向节点和当前节点的距离。 backward(后退指针)：节点中用BW字样标记节点的后退指针，指向位于当前节点的前一个节点。 score：跳跃表节点按分值由大到小排列。 obj：成员对象，指向节点保存的成员对象。 2.1跳跃表节点redis.h/zskiplistNode 123456789101112131415typedef struct zskiplistNode&#123; //层 struct zskiplistLevel&#123; //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; &#125;level[], //后退指针 struct zskiplistNode *backward; //分支 double score; //成员对象, robj *obj;&#125;zskiplistNode; 层每次创建一个新的跳跃表节点时，程序都会根据幂次定律生成一个0~32之间的数 幂次定律：越大的数生成的概率越小。 前进指针用于访问表头到表尾的节点 跨度其用途是用于计算节点在链表中的位置。 后退指针每次只能后退一个节点。 分值和成员分值用于节点间的排序。 成员对象指向一个字符串，字符串对象存放着一个SDS值。这个值代表着具体的对象类型。 2.2跳跃表实现redis.h/zskiplist 12345678typedef struct zskiplist&#123; //表头节点和表尾节点 struct zskiplistNode *header, *tail; //节点数量 int length; //表中层数最大的节点的层数 int level;&#125;zskiplist; 3总结跳跃表是有序集合的底层实现之一(另一个是压缩列表)。 跳跃表由zskiplist和zskiplistNode两个节点实现。 每个跳跃表节点的层高是1~32之间的随机数。 多个节点可以包含相同的分值，但每个节点的成员对象是唯一的。 跳跃表中节点按分值大小排序，分值相同的按对象大小排序。]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Redis</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构之字典]]></title>
    <url>%2F2019%2F05%2F19%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[Redis数据结构之字典字典是一种保存键值对的抽象数据结构。在字典中，一个键可以和一个值进行关联，这些关联的键和值就称为键值对。 Redis的数据库就是通过字典作为其底层实现的。对数据库的增删改查都是建立在字典的操作之上。 1.字典的实现Redis的字典使用hash表作为底层实现 1.1哈希表Redis字典所使用的哈希表结构定义如下 1234567891011121314typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used;&#125;dictht; dictEntry结构保存着一个键值对。size属性记录了哈希表大小，也即是table数组的大小。 used属性指的是当前哈希表目前已有节点的数量。 1.2哈希表节点哈希表节点用dictEntry结构表示，每个dictEntry结构都保存着一个键值对。 1234567891011121314typedef struct dictEntry&#123; //键 void *key; //值 union&#123; void *val; uint64_tu64; int64_ts64; &#125;v; //指向下个哈希表节点，形成链表 struct dictEntry *next;&#125;dicEntry; 其中键值对的值可以是一个指针，或者是uint64_t整数，又或者是一个int64_t整数。 next属性是指向另一个哈希表节点的指针，将多个哈希值相同的键值对连接在一起，以此来解决键冲突问题。 1.3字典Redis中字典由dict.h/dict结构表示: 123456789101112131415typedef struct dict&#123; //类型特定函数 dictType *type; //私有数据 void *privdata; //哈希表 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 int trehashidx;/*rehashing not in processing if rehashidx = -1;*/ &#125;dict; 其中type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个 dictType结构表存了一簇操作特定类型键值对的函数，redis 会为用途不同的字典设置不同类型的特定函数。 123456789101112typedef struct dictType&#123; //计算哈希值的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(*keyDup)(void *privdata, const void *key;) //复制值的函数 void *(*valDup)(void *privdata, const void *obj;) .... &#125; ht属性是一个包含了两个项的数组，数组中每一项都是dictht哈希表。一般情况下只使用ht[0],在rehash的时候才会使用ht[1]. 2哈希算法Redis计算哈希值和索引值的方法如下： 12#使用字典设置的哈希函数，计算键key的哈希值hash = dict-&gt;type-&gt;hashfunction（key）； 123#使用hash表的sizemask属性和哈希值计算出索引值#根据使用情况的不同，ht[x]可以是ht[0]或者ht[1]index = hash &amp; dict -&gt; ht[x].sizemask; 例如，我们要将一个键值对k0和v0添加到字典里面： 计算键k0的hash值，hash = dict-&gt;type-&gt;hashFunction(k0); 假设计算所得的hash值为8，那么程序会继续使用语句：index = hash&amp;dict-&gt;ht[0].sizemask = 8&amp;3 = 0; 计算出键k0的索引值为0，这表示包含键值对k0和v0的节点被放置到哈希表数组的索引0位置上 。 MurmurHash算法：Redis使用Murmurhash2 3解决键冲突键冲突的定义:当两个或者以上的键被分配到了hash表数组的同一个索引上，我们称这些键发生了冲突。 Redis的哈希表使用链地址法解决键冲突。其中由于dictEntry没有指向表尾的指针，新节点采取头插法。 4rehash为了让哈希表的负载因子在一个合理范围内，程序需要对哈希表进行扩展和收缩。 rehash的操作： 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量。 扩展操作，ht[1]的大小等于第一个ht[0].used*2的2^n 收缩操作，ht[1]的大小等于 第一个ht[0].used的2^n 2.将保存在ht[0]上的所有键值对rehash到ht[1]上,rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。 3.将ht[0]包含的所有键值对都迁移到ht[1]上，释放ht[0]，将ht[1]变成ht[0],并且创建一个新的ht[1]. 哈希表的负载因子计算： load_factor = ht[0].used / ht[0].size 5渐进式rehash扩展或者收缩得到哈希表需要将ht[0]里面的所有键值对rehash到ht[1]中，但是rehash的过程并不是一次性完成的，rehash的动作是分多次，渐进式地完成的。 详细步骤如下： 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个hash表。 在字典中维持一个索引计数器变量rehashidx,将其值设为0，表示rehash工作开始。 rehash进行期间，每次对字典进行增删改查时，除了执行指定操作，还顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]上。 随着字典操作的不断执行，最终在某个时间点ht[0]完全被rehash到ht[1]. 在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的增删改查需要在两个表上进行，例如，在ht[0]中未找到，继续到ht[1]里面进行查找。 参考文献《Redis设计与实现》–黄健宏，机械工业出版社]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Redis</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP的缺点和采取措施]]></title>
    <url>%2F2019%2F05%2F19%2FHTTP%E7%9A%84%E7%BC%BA%E7%82%B9%E5%92%8C%E9%87%87%E5%8F%96%E6%8E%AA%E6%96%BD%2F</url>
    <content type="text"><![CDATA[HTTP的缺点和采取的措施1http的主要不足 通信使用明文，内容可能会被窃听。 不验证通信方身份，可能遭遇伪装。 无法证明报文完整性,可能遭到篡改。 2http加密处理措施 通信的加密：通过SSL(secure socket layer)或者TLS(Transport Layer Security安全传输协议)的组合使用。 内容的加密：通过对通信传输内容本身加密，报文主题的内容被加密处理，这需要客户端和服务端同时具有加密和解密的能力。 3http验证通信方身份措施 HTTP协议不存在验证通信方的处理步骤，任何人都可以发送请求，无法确定请求是否到达真正的服务器，无法确定响应是否返回到真的客户端，无法确定对方是否有访问权限，无法判断请求来源，无法阻止海量DOS攻击。 使用SSL可以查明对方的证书，SSL不仅提供加密服务，而且提供证书来确定对方，证书由值得信赖的第三方机构颁发，对于服务端和客户端，持有证书即可完成身份的确认。 4http验证报文完整性的措施 接收到的内容可能有误，因为http协议无法证明通信完整性，像这样在传输途中遭遇拦截并且篡改内容的攻击称为中间人攻击。常常使用SHA-1和MD5等散列值校验的方法以及确认文件的数字签名的方法。]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好，Hexo]]></title>
    <url>%2F2019%2F05%2F19%2F%E4%BD%A0%E5%A5%BD%EF%BC%8CHexo%2F</url>
    <content type="text"><![CDATA[使用Hexo，是非常简单的事情！]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>git</tag>
        <tag>前端</tag>
      </tags>
  </entry>
</search>
